{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pandas as pd\n",
    "from preprocessing_algorithms import *\n",
    "from efficiency_scores import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"DUC/Duc_first_reference/main_dataset/Duc_dataset_first_ref_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_algorithm(filtered_sentences,sentences,size=5,num_topics = 3):\n",
    "    # Create a CountVectorizer object to preprocess the text\n",
    "    vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "    # Fit and transform the vectorizer to the text\n",
    "    doc_term_matrix = vectorizer.fit_transform(filtered_sentences)\n",
    "\n",
    "    # Create an LDA object using Gibbs sampling\n",
    "    lda = LatentDirichletAllocation(n_components=num_topics, learning_method='batch', random_state=42)\n",
    "\n",
    "    # Fit the LDA model to the document-term matrix\n",
    "    lda.fit(doc_term_matrix)\n",
    "\n",
    "    # Extract the topic summaries\n",
    "    # topic_word_distributions = lda.components_\n",
    "    # for i, topic_dist in enumerate(topic_word_distributions):\n",
    "    #     topic_words = [vectorizer.get_feature_names_out()[j] for j in topic_dist.argsort()[:-6:-1]]\n",
    "    #     #print(f\"Topic {i}: {' '.join(topic_words)}\")\n",
    "\n",
    "    # Extract the topic distribution for each sentence\n",
    "    sentence_topic_distributions = lda.transform(doc_term_matrix)\n",
    "\n",
    "    # Calculate the sentence scores\n",
    "    sentence_scores = sentence_topic_distributions.max(axis=1)\n",
    "\n",
    "    # Sort the sentences by score in descending order\n",
    "    sorted_indices = sentence_scores.argsort()[::-1]\n",
    "\n",
    "    # Extract the top N sentences\n",
    "    top_indices = sorted_indices[:size]\n",
    "    top_sentences = [sentences[i] for i in top_indices]\n",
    "\n",
    "    # Print the summary\n",
    "    #print('\\n'.join(top_sentences))\n",
    "    #return '\\n'.join(top_sentences)\n",
    "\n",
    "\n",
    "    return sentence_scores,top_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=lda_algorithm(filtered_sentences[0],sentences[0],size=5,num_topics = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96018969, 0.9670082 , 0.77459361, 0.81176497, 0.93642922,\n",
       "       0.9105937 , 0.82058664, 0.84661508, 0.96348233, 0.93680854,\n",
       "       0.95153653, 0.9431008 , 0.93661272, 0.95616754, 0.61601804,\n",
       "       0.94910596, 0.94016991, 0.93853424, 0.52329622, 0.95459736,\n",
       "       0.97366052, 0.86188048, 0.95354084, 0.96044855, 0.92854243,\n",
       "       0.94189826, 0.95859064, 0.58023741, 0.91074354, 0.94340103,\n",
       "       0.94267263, 0.97247596, 0.93632829, 0.94060055, 0.92948819,\n",
       "       0.90033413, 0.92966308, 0.94032813, 0.9428774 , 0.89657909,\n",
       "       0.93906278, 0.89513618, 0.94744763, 0.94939869, 0.95518408,\n",
       "       0.61232498, 0.970469  , 0.89914135, 0.9627204 , 0.95333145,\n",
       "       0.93220822, 0.59300067, 0.93260491, 0.9299379 , 0.95545459,\n",
       "       0.73910232, 0.9564791 , 0.9578388 , 0.87547007, 0.70281251,\n",
       "       0.95769758, 0.98123423, 0.91253803, 0.96562673, 0.95817952,\n",
       "       0.94687807, 0.96096352, 0.60569337, 0.9454253 , 0.93899959,\n",
       "       0.93934049, 0.91147387, 0.93312639, 0.97009472, 0.92127176,\n",
       "       0.96097906, 0.9549029 , 0.94676466, 0.96406184, 0.94794168,\n",
       "       0.93000765, 0.95878944, 0.95467071, 0.96361118, 0.93093454,\n",
       "       0.88296463, 0.89982715, 0.50285408, 0.96771928, 0.95307026,\n",
       "       0.9655132 , 0.53654274, 0.49900606, 0.9135554 , 0.96029764,\n",
       "       0.63790264, 0.76808253, 0.97149467, 0.49101497, 0.88304424,\n",
       "       0.93124346, 0.93816524, 0.95282576, 0.85846526, 0.65559538,\n",
       "       0.85764631, 0.68967408, 0.96441485, 0.89673207, 0.96222741,\n",
       "       0.9668678 , 0.96012815, 0.95262756, 0.96123016, 0.94993414,\n",
       "       0.96687487, 0.94178524, 0.90671539, 0.92301197, 0.94704347,\n",
       "       0.93202963, 0.93606222, 0.92985479, 0.69200371, 0.9663611 ,\n",
       "       0.93041583, 0.92050818, 0.96694727, 0.95530087, 0.9499677 ,\n",
       "       0.6177942 , 0.92503636, 0.95072057, 0.82167742, 0.95291855,\n",
       "       0.96127759, 0.91468282, 0.88331879, 0.86321184, 0.78715806,\n",
       "       0.93763272, 0.95104274, 0.76688728, 0.96001777, 0.96374719,\n",
       "       0.96068613, 0.96909773, 0.92762963, 0.95831723, 0.85939402,\n",
       "       0.88032412, 0.94589031, 0.92947388, 0.56311799, 0.95625514,\n",
       "       0.67546388, 0.93504916, 0.64866299, 0.96123333, 0.96938777,\n",
       "       0.92974081, 0.93647128, 0.84757241, 0.92299874, 0.93429016,\n",
       "       0.95578612, 0.93826366, 0.98006078, 0.9560137 , 0.96961684,\n",
       "       0.95523807, 0.95934828, 0.92980761, 0.50989978, 0.95515138,\n",
       "       0.9295651 , 0.9462397 , 0.95987997, 0.96543468, 0.96411008,\n",
       "       0.97245888, 0.94466245, 0.96502554, 0.97946879, 0.94294618,\n",
       "       0.93641129, 0.95276961, 0.93043651])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
