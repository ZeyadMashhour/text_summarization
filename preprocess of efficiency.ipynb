{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e110610-31f5-453d-b4dc-da748aad72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.text.rouge import ROUGEScore\n",
    "rouge = ROUGEScore()\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f96796f1-fd20-450a-b79d-366330328c89",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0fda335d-31f1-4c05-a06d-669b5263038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8c729eb-1ca7-473a-9ce5-7b784b1a6520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from summarization_algorithm import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d3a1ace-3ef7-45bb-896e-6b5e68b17aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Daman and Diu administration on Wednesday ...</td>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From her special numbers to TV?appearances, Bo...</td>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hotels in Mumbai and other Indian cities are t...</td>\n",
       "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An alleged suspect in a kidnapping case was fo...</td>\n",
       "      <td>A 32-year-old man on Wednesday was found hangi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Facing pressure from President Donald Trump to...</td>\n",
       "      <td>The US Air Force is negotiating with Boeing to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Allahabad, Aug 01 (PTI) The Allahabad High Cou...</td>\n",
       "      <td>The Allahabad High Court on Tuesday said it wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Motorman Mahendra Prasad called up the railway...</td>\n",
       "      <td>As many as 13 people died while travelling in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Bored in confines of a sprawling resort in Ben...</td>\n",
       "      <td>The Gujarat Congress MLAs staying in a Bengalu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>There is only a 5% chance that the Earth will ...</td>\n",
       "      <td>According to a recently published US-based res...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             original  \\\n",
       "0   The Daman and Diu administration on Wednesday ...   \n",
       "1   From her special numbers to TV?appearances, Bo...   \n",
       "2   The Indira Gandhi Institute of Medical Science...   \n",
       "3   Hotels in Mumbai and other Indian cities are t...   \n",
       "4   An alleged suspect in a kidnapping case was fo...   \n",
       "..                                                ...   \n",
       "95  Facing pressure from President Donald Trump to...   \n",
       "96  Allahabad, Aug 01 (PTI) The Allahabad High Cou...   \n",
       "97  Motorman Mahendra Prasad called up the railway...   \n",
       "98  Bored in confines of a sprawling resort in Ben...   \n",
       "99  There is only a 5% chance that the Earth will ...   \n",
       "\n",
       "                                              summary  \n",
       "0   The Administration of Union Territory Daman an...  \n",
       "1   Malaika Arora slammed an Instagram user who tr...  \n",
       "2   The Indira Gandhi Institute of Medical Science...  \n",
       "3   Hotels in Maharashtra will train their staff t...  \n",
       "4   A 32-year-old man on Wednesday was found hangi...  \n",
       "..                                                ...  \n",
       "95  The US Air Force is negotiating with Boeing to...  \n",
       "96  The Allahabad High Court on Tuesday said it wo...  \n",
       "97  As many as 13 people died while travelling in ...  \n",
       "98  The Gujarat Congress MLAs staying in a Bengalu...  \n",
       "99  According to a recently published US-based res...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset.csv\")\n",
    "df=df.iloc[:,1:]#remove first column(unnamed col)\n",
    "df.dropna(inplace=True)\n",
    "columns_titles = [\"original\",\"summary\"]\n",
    "df=df.reindex(columns=columns_titles)\n",
    "mini_df = df[:100]\n",
    "mini_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0898d345-4f72-4c63-8460-2301fa29a34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocessing(text):\n",
    "#     sentences = text\n",
    "\n",
    "#     # Load the model (English) into spaCy\n",
    "#     nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#     # Adding 'sentencizer' component to the pipeline\n",
    "#     nlp.add_pipe('sentencizer')\n",
    "\n",
    "#     # Tokenization & Lemmatization\n",
    "#     lemmatized_sentences = []\n",
    "\n",
    "#     doc = nlp(sentences)\n",
    "\n",
    "#     sentences = []\n",
    "#     for sentence in doc.sents:\n",
    "#         sentences.append(sentence.text)\n",
    "#         lemmatized_sentences.append([token.lemma_ for token in sentence])\n",
    "\n",
    "\n",
    "#     # Removing Stop Words & Punctuation \n",
    "#     filtered_sentences = []\n",
    "\n",
    "#     for sentences_group in lemmatized_sentences:\n",
    "#         filtered = \"\"\n",
    "\n",
    "#         for sentence in sentences_group:\n",
    "#             sentence_doc = nlp(sentence)\n",
    "#             words_of_sentence = [token.text for token in sentence_doc]\n",
    "\n",
    "#             for token in sentence_doc:\n",
    "#                 if token.is_stop == False and token.text.isalpha() == True:\n",
    "#                     filtered += token.text + \" \"\n",
    "\n",
    "#         filtered_sentences.append(filtered)\n",
    "\n",
    "#     return sentences, filtered_sentences\n",
    "\n",
    "def preprocessing(text, lemmatization = False):\n",
    "    sentences = text\n",
    "\n",
    "    # Load the model (English) into spaCy\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "    # Adding 'sentencizer' component to the pipeline\n",
    "    nlp.add_pipe('sentencizer')\n",
    "\n",
    "    # Tokenization & Lemmatization\n",
    "    lemmatized_sentences = []\n",
    "\n",
    "    doc = nlp(sentences)\n",
    "\n",
    "    sentences = []\n",
    "    if(lemmatization):\n",
    "        for sentence in doc.sents:\n",
    "            sentences.append(sentence.text)\n",
    "            lemmatized_sentences.append([token.lemma_ for token in sentence])\n",
    "    else:\n",
    "        for sentence in doc.sents:\n",
    "            sentences.append(sentence.text)\n",
    "            lemmatized_sentences.append([token.text for token in sentence])\n",
    "\n",
    "\n",
    "\n",
    "    # Removing Stop Words & Punctuation \n",
    "    filtered_sentences = []\n",
    "\n",
    "    for sentences_group in lemmatized_sentences:\n",
    "        filtered = \"\"\n",
    "\n",
    "        for sentence in sentences_group:\n",
    "            sentence_doc = nlp(sentence)\n",
    "            words_of_sentence = [token.text for token in sentence_doc]\n",
    "\n",
    "            for token in sentence_doc:\n",
    "                if token.is_stop == False and token.text.isalpha() == True:\n",
    "                    filtered += token.text + \" \"\n",
    "\n",
    "        filtered_sentences.append(filtered)\n",
    "\n",
    "    return sentences, filtered_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe43efe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows,columns = mini_df.shape\n",
    "articles_sentences,filtered_articles =[],[] \n",
    "for row in range(100):\n",
    "    articles_sentence , filtered_article = preprocessing(mini_df.iloc[row,0])\n",
    "    articles_sentences.append(articles_sentence)\n",
    "    filtered_articles.append(filtered_article)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "696f1924-2caa-4fcf-a4ff-02d3bf801eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_with(articles_sentences,filtered_articles ,summary_algorithm,size = 2):\n",
    "    rows = len(articles_sentences)\n",
    "    rows = 100#uncomment this for runtime speed\n",
    "    summarized_text = []\n",
    "    for row in range(rows):\n",
    "        sentences=articles_sentences[row]\n",
    "        filtered_sentences = filtered_articles[row]\n",
    "                                  #(filtered_sentences,sentence)\n",
    "        summary = summary_algorithm(filtered_sentences,sentences,size)\n",
    "        summarized_text.append(summary)\n",
    "    summary_df = pd.DataFrame (summarized_text, columns = [f'{summary_algorithm.__name__} summary'])\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2e7badc-7681-4f39-8693-3f6bcb8a7d47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "luhn = summarize_with(articles_sentences,filtered_articles ,luhn_algorithm).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4353565",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_matching = summarize_with(articles_sentences,filtered_articles ,text_matching_algorithm).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "445152f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa = summarize_with(articles_sentences,filtered_articles ,lsa_summarization).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b117db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\PycharmProjects\\NLP\\text_summarization\\summarization_algorithm.py:195: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  new_tf_idf[row,col] = tf_idf[row,col]/sent_length[row]\n"
     ]
    }
   ],
   "source": [
    "LexRank = summarize_with(articles_sentences,filtered_articles ,LexRank_algorithm).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd22f1cf-4763-435b-9674-f722a603d1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>summary</th>\n",
       "      <th>luhn_algorithm summary</th>\n",
       "      <th>lsa_summarization summary</th>\n",
       "      <th>text_matching_algorithm summary</th>\n",
       "      <th>LexRank_algorithm summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Daman and Diu administration on Wednesday ...</td>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "      <td>The Daman and Diu administration on Wednesday ...</td>\n",
       "      <td>The RSS is the ideological parent of the rulin...</td>\n",
       "      <td>The Daman and Diu administration on Wednesday ...</td>\n",
       "      <td>The union territory?s administration was force...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From her special numbers to TV?appearances, Bo...</td>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "      <td>A post shared by Malaika Arora Khan (@malaikaa...</td>\n",
       "      <td>(read alimony) money to wear ?short clothes an...</td>\n",
       "      <td>A post shared by Malaika Arora Khan (@malaikaa...</td>\n",
       "      <td>The details of the alimony are only known to M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>In its response, the management of the autonom...</td>\n",
       "      <td>on the marital declaration form be immediately...</td>\n",
       "      <td>IGIMS medical superintendent Dr Manish Mandal ...</td>\n",
       "      <td>on the marital declaration form be immediately...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hotels in Mumbai and other Indian cities are t...</td>\n",
       "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
       "      <td>Human trafficking is the world's fastest growi...</td>\n",
       "      <td>RESCUE ME APPThe Rescue Me app - to be launche...</td>\n",
       "      <td>Last year, major hotel groups, including the H...</td>\n",
       "      <td>Awsarmmel said hotels would be told about 50 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An alleged suspect in a kidnapping case was fo...</td>\n",
       "      <td>A 32-year-old man on Wednesday was found hangi...</td>\n",
       "      <td>A native of Kasganj in UP, Kumar was unmarried...</td>\n",
       "      <td>Kumar was one of them,?Their relationship ende...</td>\n",
       "      <td>A team was sent to Kumar?s village but when he...</td>\n",
       "      <td>said a police officer.said the officer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Facing pressure from President Donald Trump to...</td>\n",
       "      <td>The US Air Force is negotiating with Boeing to...</td>\n",
       "      <td>Facing pressure from President Donald Trump to...</td>\n",
       "      <td>Boeing built two 747-8s out of an order of fou...</td>\n",
       "      <td>Facing pressure from President Donald Trump to...</td>\n",
       "      <td>Boeing built two 747-8s out of an order of fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Allahabad, Aug 01 (PTI) The Allahabad High Cou...</td>\n",
       "      <td>The Allahabad High Court on Tuesday said it wo...</td>\n",
       "      <td>The Allahabad High Court today said it would h...</td>\n",
       "      <td>Allahabad, Aug 01 (PTI)The Allahabad High Cour...</td>\n",
       "      <td>The Allahabad High Court today said it would h...</td>\n",
       "      <td>The Allahabad High Court today said it would h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Motorman Mahendra Prasad called up the railway...</td>\n",
       "      <td>As many as 13 people died while travelling in ...</td>\n",
       "      <td>Motorman Mahendra Prasad called up the railway...</td>\n",
       "      <td>Last year, out of 3,202 deaths recorded, a maj...</td>\n",
       "      <td>According to the railway data, 348 people died...</td>\n",
       "      <td>Crossing tracks led to 1,798 of 3,202 train fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Bored in confines of a sprawling resort in Ben...</td>\n",
       "      <td>The Gujarat Congress MLAs staying in a Bengalu...</td>\n",
       "      <td>Following strict orders of the Karnataka Power...</td>\n",
       "      <td>Bored in confines of a sprawling resort in Ben...</td>\n",
       "      <td>Following strict orders of the Karnataka Power...</td>\n",
       "      <td>The MLAs who were allowed to go out are suppos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>There is only a 5% chance that the Earth will ...</td>\n",
       "      <td>According to a recently published US-based res...</td>\n",
       "      <td>Rather than look at how greenhouse gases will ...</td>\n",
       "      <td>It has long been acknowledged that emissions c...</td>\n",
       "      <td>Rather than look at how greenhouse gases will ...</td>\n",
       "      <td>Fortunately, renewables, storage and other tec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             original  \\\n",
       "0   The Daman and Diu administration on Wednesday ...   \n",
       "1   From her special numbers to TV?appearances, Bo...   \n",
       "2   The Indira Gandhi Institute of Medical Science...   \n",
       "3   Hotels in Mumbai and other Indian cities are t...   \n",
       "4   An alleged suspect in a kidnapping case was fo...   \n",
       "..                                                ...   \n",
       "95  Facing pressure from President Donald Trump to...   \n",
       "96  Allahabad, Aug 01 (PTI) The Allahabad High Cou...   \n",
       "97  Motorman Mahendra Prasad called up the railway...   \n",
       "98  Bored in confines of a sprawling resort in Ben...   \n",
       "99  There is only a 5% chance that the Earth will ...   \n",
       "\n",
       "                                              summary  \\\n",
       "0   The Administration of Union Territory Daman an...   \n",
       "1   Malaika Arora slammed an Instagram user who tr...   \n",
       "2   The Indira Gandhi Institute of Medical Science...   \n",
       "3   Hotels in Maharashtra will train their staff t...   \n",
       "4   A 32-year-old man on Wednesday was found hangi...   \n",
       "..                                                ...   \n",
       "95  The US Air Force is negotiating with Boeing to...   \n",
       "96  The Allahabad High Court on Tuesday said it wo...   \n",
       "97  As many as 13 people died while travelling in ...   \n",
       "98  The Gujarat Congress MLAs staying in a Bengalu...   \n",
       "99  According to a recently published US-based res...   \n",
       "\n",
       "                               luhn_algorithm summary  \\\n",
       "0   The Daman and Diu administration on Wednesday ...   \n",
       "1   A post shared by Malaika Arora Khan (@malaikaa...   \n",
       "2   In its response, the management of the autonom...   \n",
       "3   Human trafficking is the world's fastest growi...   \n",
       "4   A native of Kasganj in UP, Kumar was unmarried...   \n",
       "..                                                ...   \n",
       "95  Facing pressure from President Donald Trump to...   \n",
       "96  The Allahabad High Court today said it would h...   \n",
       "97  Motorman Mahendra Prasad called up the railway...   \n",
       "98  Following strict orders of the Karnataka Power...   \n",
       "99  Rather than look at how greenhouse gases will ...   \n",
       "\n",
       "                            lsa_summarization summary  \\\n",
       "0   The RSS is the ideological parent of the rulin...   \n",
       "1   (read alimony) money to wear ?short clothes an...   \n",
       "2   on the marital declaration form be immediately...   \n",
       "3   RESCUE ME APPThe Rescue Me app - to be launche...   \n",
       "4   Kumar was one of them,?Their relationship ende...   \n",
       "..                                                ...   \n",
       "95  Boeing built two 747-8s out of an order of fou...   \n",
       "96  Allahabad, Aug 01 (PTI)The Allahabad High Cour...   \n",
       "97  Last year, out of 3,202 deaths recorded, a maj...   \n",
       "98  Bored in confines of a sprawling resort in Ben...   \n",
       "99  It has long been acknowledged that emissions c...   \n",
       "\n",
       "                      text_matching_algorithm summary  \\\n",
       "0   The Daman and Diu administration on Wednesday ...   \n",
       "1   A post shared by Malaika Arora Khan (@malaikaa...   \n",
       "2   IGIMS medical superintendent Dr Manish Mandal ...   \n",
       "3   Last year, major hotel groups, including the H...   \n",
       "4   A team was sent to Kumar?s village but when he...   \n",
       "..                                                ...   \n",
       "95  Facing pressure from President Donald Trump to...   \n",
       "96  The Allahabad High Court today said it would h...   \n",
       "97  According to the railway data, 348 people died...   \n",
       "98  Following strict orders of the Karnataka Power...   \n",
       "99  Rather than look at how greenhouse gases will ...   \n",
       "\n",
       "                            LexRank_algorithm summary  \n",
       "0   The union territory?s administration was force...  \n",
       "1   The details of the alimony are only known to M...  \n",
       "2   on the marital declaration form be immediately...  \n",
       "3   Awsarmmel said hotels would be told about 50 s...  \n",
       "4             said a police officer.said the officer.  \n",
       "..                                                ...  \n",
       "95  Boeing built two 747-8s out of an order of fou...  \n",
       "96  The Allahabad High Court today said it would h...  \n",
       "97  Crossing tracks led to 1,798 of 3,202 train fa...  \n",
       "98  The MLAs who were allowed to go out are suppos...  \n",
       "99  Fortunately, renewables, storage and other tec...  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizontal_concat_df = pd.concat(\n",
    "    [\n",
    "        mini_df,\n",
    "        luhn,\n",
    "        lsa,\n",
    "        text_matching,\n",
    "        LexRank\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "#horizontal_concat_df[horizontal_concat_df.isnull().any(axis=1)]\n",
    "horizontal_concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "95220831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_efficiency(predicted_summary,original_summary):\n",
    "    rouge = ROUGEScore()\n",
    "    return rouge(predicted_summary, original_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b0b5234-c2a1-4c83-bcad-978cc3223f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_sentences_efficiency(df,algorithm_summary_df):\n",
    "    sentences_efficiency = []\n",
    "    rows, column = algorithm_summary_df.shape\n",
    "    rows = 100\n",
    "    for row in range(rows):\n",
    "        predicted_summary = algorithm_summary_df.iloc[row,0]\n",
    "        original_summary = df.iloc[row,0]\n",
    "        efficiency_dict = calculate_efficiency(predicted_summary,original_summary)\n",
    "        sentences_efficiency.append(efficiency_dict)\n",
    "              \n",
    "    dataframe = pd.DataFrame(sentences_efficiency)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "53abdee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>luhn_algorithm summary</th>\n",
       "      <th>rouge1_fmeasure</th>\n",
       "      <th>rouge1_precision</th>\n",
       "      <th>rouge1_recall</th>\n",
       "      <th>rouge2_fmeasure</th>\n",
       "      <th>rouge2_precision</th>\n",
       "      <th>rouge2_recall</th>\n",
       "      <th>rougeL_fmeasure</th>\n",
       "      <th>rougeL_precision</th>\n",
       "      <th>rougeL_recall</th>\n",
       "      <th>rougeLsum_fmeasure</th>\n",
       "      <th>rougeLsum_precision</th>\n",
       "      <th>rougeLsum_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Daman and Diu administration on Wednesday ...</td>\n",
       "      <td>tensor(0.3370)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.2027)</td>\n",
       "      <td>tensor(0.3341)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.2005)</td>\n",
       "      <td>tensor(0.3370)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.2027)</td>\n",
       "      <td>tensor(0.3370)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.2027)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A post shared by Malaika Arora Khan (@malaikaa...</td>\n",
       "      <td>tensor(0.3783)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.2333)</td>\n",
       "      <td>tensor(0.3758)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.2313)</td>\n",
       "      <td>tensor(0.3783)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.2333)</td>\n",
       "      <td>tensor(0.3783)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.2333)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In its response, the management of the autonom...</td>\n",
       "      <td>tensor(0.3081)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.1821)</td>\n",
       "      <td>tensor(0.2998)</td>\n",
       "      <td>tensor(0.9839)</td>\n",
       "      <td>tensor(0.1768)</td>\n",
       "      <td>tensor(0.2152)</td>\n",
       "      <td>tensor(0.6984)</td>\n",
       "      <td>tensor(0.1272)</td>\n",
       "      <td>tensor(0.3081)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.1821)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Human trafficking is the world's fastest growi...</td>\n",
       "      <td>tensor(0.2613)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.1503)</td>\n",
       "      <td>tensor(0.2557)</td>\n",
       "      <td>tensor(0.9875)</td>\n",
       "      <td>tensor(0.1468)</td>\n",
       "      <td>tensor(0.1645)</td>\n",
       "      <td>tensor(0.6296)</td>\n",
       "      <td>tensor(0.0946)</td>\n",
       "      <td>tensor(0.2613)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.1503)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A native of Kasganj in UP, Kumar was unmarried...</td>\n",
       "      <td>tensor(0.3333)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.2000)</td>\n",
       "      <td>tensor(0.3263)</td>\n",
       "      <td>tensor(0.9872)</td>\n",
       "      <td>tensor(0.1954)</td>\n",
       "      <td>tensor(0.2532)</td>\n",
       "      <td>tensor(0.7595)</td>\n",
       "      <td>tensor(0.1519)</td>\n",
       "      <td>tensor(0.3333)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Facing pressure from President Donald Trump to...</td>\n",
       "      <td>tensor(0.4046)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.2536)</td>\n",
       "      <td>tensor(0.3985)</td>\n",
       "      <td>tensor(0.9904)</td>\n",
       "      <td>tensor(0.2494)</td>\n",
       "      <td>tensor(0.4046)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.2536)</td>\n",
       "      <td>tensor(0.4046)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.2536)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>The Allahabad High Court today said it would h...</td>\n",
       "      <td>tensor(0.8058)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.6748)</td>\n",
       "      <td>tensor(0.8039)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.6721)</td>\n",
       "      <td>tensor(0.8058)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.6748)</td>\n",
       "      <td>tensor(0.8058)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.6748)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Motorman Mahendra Prasad called up the railway...</td>\n",
       "      <td>tensor(0.3636)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.2222)</td>\n",
       "      <td>tensor(0.3553)</td>\n",
       "      <td>tensor(0.9859)</td>\n",
       "      <td>tensor(0.2167)</td>\n",
       "      <td>tensor(0.3636)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.2222)</td>\n",
       "      <td>tensor(0.3636)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.2222)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Following strict orders of the Karnataka Power...</td>\n",
       "      <td>tensor(0.5430)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.3727)</td>\n",
       "      <td>tensor(0.5235)</td>\n",
       "      <td>tensor(0.9750)</td>\n",
       "      <td>tensor(0.3578)</td>\n",
       "      <td>tensor(0.3709)</td>\n",
       "      <td>tensor(0.6829)</td>\n",
       "      <td>tensor(0.2545)</td>\n",
       "      <td>tensor(0.5430)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.3727)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Rather than look at how greenhouse gases will ...</td>\n",
       "      <td>tensor(0.1798)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.0988)</td>\n",
       "      <td>tensor(0.1764)</td>\n",
       "      <td>tensor(0.9895)</td>\n",
       "      <td>tensor(0.0968)</td>\n",
       "      <td>tensor(0.1798)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.0988)</td>\n",
       "      <td>tensor(0.1798)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.0988)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               luhn_algorithm summary rouge1_fmeasure  \\\n",
       "0   The Daman and Diu administration on Wednesday ...  tensor(0.3370)   \n",
       "1   A post shared by Malaika Arora Khan (@malaikaa...  tensor(0.3783)   \n",
       "2   In its response, the management of the autonom...  tensor(0.3081)   \n",
       "3   Human trafficking is the world's fastest growi...  tensor(0.2613)   \n",
       "4   A native of Kasganj in UP, Kumar was unmarried...  tensor(0.3333)   \n",
       "..                                                ...             ...   \n",
       "95  Facing pressure from President Donald Trump to...  tensor(0.4046)   \n",
       "96  The Allahabad High Court today said it would h...  tensor(0.8058)   \n",
       "97  Motorman Mahendra Prasad called up the railway...  tensor(0.3636)   \n",
       "98  Following strict orders of the Karnataka Power...  tensor(0.5430)   \n",
       "99  Rather than look at how greenhouse gases will ...  tensor(0.1798)   \n",
       "\n",
       "   rouge1_precision   rouge1_recall rouge2_fmeasure rouge2_precision  \\\n",
       "0        tensor(1.)  tensor(0.2027)  tensor(0.3341)       tensor(1.)   \n",
       "1        tensor(1.)  tensor(0.2333)  tensor(0.3758)       tensor(1.)   \n",
       "2        tensor(1.)  tensor(0.1821)  tensor(0.2998)   tensor(0.9839)   \n",
       "3        tensor(1.)  tensor(0.1503)  tensor(0.2557)   tensor(0.9875)   \n",
       "4        tensor(1.)  tensor(0.2000)  tensor(0.3263)   tensor(0.9872)   \n",
       "..              ...             ...             ...              ...   \n",
       "95       tensor(1.)  tensor(0.2536)  tensor(0.3985)   tensor(0.9904)   \n",
       "96       tensor(1.)  tensor(0.6748)  tensor(0.8039)       tensor(1.)   \n",
       "97       tensor(1.)  tensor(0.2222)  tensor(0.3553)   tensor(0.9859)   \n",
       "98       tensor(1.)  tensor(0.3727)  tensor(0.5235)   tensor(0.9750)   \n",
       "99       tensor(1.)  tensor(0.0988)  tensor(0.1764)   tensor(0.9895)   \n",
       "\n",
       "     rouge2_recall rougeL_fmeasure rougeL_precision   rougeL_recall  \\\n",
       "0   tensor(0.2005)  tensor(0.3370)       tensor(1.)  tensor(0.2027)   \n",
       "1   tensor(0.2313)  tensor(0.3783)       tensor(1.)  tensor(0.2333)   \n",
       "2   tensor(0.1768)  tensor(0.2152)   tensor(0.6984)  tensor(0.1272)   \n",
       "3   tensor(0.1468)  tensor(0.1645)   tensor(0.6296)  tensor(0.0946)   \n",
       "4   tensor(0.1954)  tensor(0.2532)   tensor(0.7595)  tensor(0.1519)   \n",
       "..             ...             ...              ...             ...   \n",
       "95  tensor(0.2494)  tensor(0.4046)       tensor(1.)  tensor(0.2536)   \n",
       "96  tensor(0.6721)  tensor(0.8058)       tensor(1.)  tensor(0.6748)   \n",
       "97  tensor(0.2167)  tensor(0.3636)       tensor(1.)  tensor(0.2222)   \n",
       "98  tensor(0.3578)  tensor(0.3709)   tensor(0.6829)  tensor(0.2545)   \n",
       "99  tensor(0.0968)  tensor(0.1798)       tensor(1.)  tensor(0.0988)   \n",
       "\n",
       "   rougeLsum_fmeasure rougeLsum_precision rougeLsum_recall  \n",
       "0      tensor(0.3370)          tensor(1.)   tensor(0.2027)  \n",
       "1      tensor(0.3783)          tensor(1.)   tensor(0.2333)  \n",
       "2      tensor(0.3081)          tensor(1.)   tensor(0.1821)  \n",
       "3      tensor(0.2613)          tensor(1.)   tensor(0.1503)  \n",
       "4      tensor(0.3333)          tensor(1.)   tensor(0.2000)  \n",
       "..                ...                 ...              ...  \n",
       "95     tensor(0.4046)          tensor(1.)   tensor(0.2536)  \n",
       "96     tensor(0.8058)          tensor(1.)   tensor(0.6748)  \n",
       "97     tensor(0.3636)          tensor(1.)   tensor(0.2222)  \n",
       "98     tensor(0.5430)          tensor(1.)   tensor(0.3727)  \n",
       "99     tensor(0.1798)          tensor(1.)   tensor(0.0988)  \n",
       "\n",
       "[100 rows x 13 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luhn_with_scores = pd.concat([luhn,df_sentences_efficiency(mini_df,luhn)],axis = 1)\n",
    "luhn_with_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "368a02ff-705c-4604-bf06-18b1416519a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m luhn_with_scores \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([luhn,df_sentences_efficiency(mini_df,luhn)],axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m text_matching_with_scores \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([text_matching,df_sentences_efficiency(mini_df,text_matching)],axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m lsa_with_scores \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([lsa,df_sentences_efficiency(mini_df,lsa)],axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m LexRank_with_scores \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([LexRank,df_sentences_efficiency(mini_df,LexRank)],axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[47], line 8\u001b[0m, in \u001b[0;36mdf_sentences_efficiency\u001b[1;34m(df, summary_df)\u001b[0m\n\u001b[0;32m      6\u001b[0m     predicted_summary \u001b[39m=\u001b[39m summary_df\u001b[39m.\u001b[39miloc[row,\u001b[39m0\u001b[39m]\n\u001b[0;32m      7\u001b[0m     original_summary \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[row,\u001b[39m0\u001b[39m]\n\u001b[1;32m----> 8\u001b[0m     efficiency_dict \u001b[39m=\u001b[39m calculate_efficiency(predicted_summary,original_summary)\n\u001b[0;32m      9\u001b[0m     sentences_efficiency\u001b[39m.\u001b[39mappend(efficiency_dict)\n\u001b[0;32m     11\u001b[0m dataframe \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(sentences_efficiency)\n",
      "Cell \u001b[1;32mIn[46], line 3\u001b[0m, in \u001b[0;36mcalculate_efficiency\u001b[1;34m(predicted_summary, original_summary)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalculate_efficiency\u001b[39m(predicted_summary,original_summary):\n\u001b[0;32m      2\u001b[0m     rouge \u001b[39m=\u001b[39m ROUGEScore()\n\u001b[1;32m----> 3\u001b[0m     \u001b[39mreturn\u001b[39;00m rouge(predicted_summary, original_summary)\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchmetrics\\metric.py:233\u001b[0m, in \u001b[0;36mMetric.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[39mraise\u001b[39;00m TorchMetricsUserError(\n\u001b[0;32m    228\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe Metric shouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be synced when performing ``forward``. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mHINT: Did you forget to call ``unsync`` ?.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m     )\n\u001b[0;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfull_state_update \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfull_state_update \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdist_sync_on_step:\n\u001b[1;32m--> 233\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_full_state_update(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    234\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_reduce_state_update(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchmetrics\\metric.py:262\u001b[0m, in \u001b[0;36mMetric._forward_full_state_update\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_grad \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m  \u001b[39m# allow grads for batch computation\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset()\n\u001b[1;32m--> 262\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m batch_val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute()\n\u001b[0;32m    265\u001b[0m \u001b[39m# restore context\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchmetrics\\metric.py:389\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_grad):\n\u001b[0;32m    388\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 389\u001b[0m         update(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    390\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    391\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected all tensors to be on\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(err):\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchmetrics\\text\\rouge.py:150\u001b[0m, in \u001b[0;36mROUGEScore.update\u001b[1;34m(self, preds, target)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(target, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    148\u001b[0m     target \u001b[39m=\u001b[39m [[target]]\n\u001b[1;32m--> 150\u001b[0m output: Dict[Union[\u001b[39mint\u001b[39m, \u001b[39mstr\u001b[39m], List[Dict[\u001b[39mstr\u001b[39m, Tensor]]] \u001b[39m=\u001b[39m _rouge_score_update(\n\u001b[0;32m    151\u001b[0m     preds,\n\u001b[0;32m    152\u001b[0m     target,\n\u001b[0;32m    153\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrouge_keys_values,\n\u001b[0;32m    154\u001b[0m     stemmer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstemmer,\n\u001b[0;32m    155\u001b[0m     normalizer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalizer,\n\u001b[0;32m    156\u001b[0m     tokenizer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer,\n\u001b[0;32m    157\u001b[0m     accumulate\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccumulate,\n\u001b[0;32m    158\u001b[0m )\n\u001b[0;32m    159\u001b[0m \u001b[39mfor\u001b[39;00m rouge_key, metrics \u001b[39min\u001b[39;00m output\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    160\u001b[0m     \u001b[39mfor\u001b[39;00m metric \u001b[39min\u001b[39;00m metrics:\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchmetrics\\functional\\text\\rouge.py:375\u001b[0m, in \u001b[0;36m_rouge_score_update\u001b[1;34m(preds, target, rouge_keys_values, accumulate, stemmer, normalizer, tokenizer)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[39mif\u001b[39;00m accumulate \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbest\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    374\u001b[0m     key_curr \u001b[39m=\u001b[39m rouge_keys_values[\u001b[39m0\u001b[39m]\n\u001b[1;32m--> 375\u001b[0m     all_fmeasure \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor([v[key_curr][\u001b[39m\"\u001b[39;49m\u001b[39mfmeasure\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39mfor\u001b[39;49;00m v \u001b[39min\u001b[39;49;00m list_results])\n\u001b[0;32m    376\u001b[0m     highest_idx \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(torch\u001b[39m.\u001b[39margmax(all_fmeasure)\u001b[39m.\u001b[39mitem())\n\u001b[0;32m    378\u001b[0m     \u001b[39mfor\u001b[39;00m rouge_key \u001b[39min\u001b[39;00m rouge_keys_values:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "luhn_with_scores = pd.concat([luhn,df_sentences_efficiency(mini_df,luhn)],axis = 1)\n",
    "text_matching_with_scores = pd.concat([text_matching,df_sentences_efficiency(mini_df,text_matching)],axis = 1)\n",
    "lsa_with_scores = pd.concat([lsa,df_sentences_efficiency(mini_df,lsa)],axis = 1)\n",
    "LexRank_with_scores = pd.concat([LexRank,df_sentences_efficiency(mini_df,LexRank)],axis = 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "afbd2e3b20535035cb123f2b315173d4c27faa26889583774d241154cf5dbaf6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
