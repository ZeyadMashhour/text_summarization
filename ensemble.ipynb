{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39m# Define the summarization models\u001b[39;00m\n\u001b[0;32m     19\u001b[0m lexrank_model \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m text: lexrank_summarize(text)\n\u001b[1;32m---> 20\u001b[0m lsa_model \u001b[39m=\u001b[39m TfidfModel(corpus)\n\u001b[0;32m     21\u001b[0m corpus_tfidf \u001b[39m=\u001b[39m lsa_model[corpus]\n\u001b[0;32m     22\u001b[0m dictionary \u001b[39m=\u001b[39m corpora\u001b[39m.\u001b[39mDictionary(corpus)\n",
      "File \u001b[1;32mc:\\Users\\basel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\models\\tfidfmodel.py:384\u001b[0m, in \u001b[0;36mTfidfModel.__init__\u001b[1;34m(self, corpus, id2word, dictionary, wlocal, wglobal, normalize, smartirs, pivot, slope)\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid2word \u001b[39m=\u001b[39m dictionary\n\u001b[0;32m    383\u001b[0m \u001b[39melif\u001b[39;00m corpus:\n\u001b[1;32m--> 384\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitialize(corpus)\n\u001b[0;32m    385\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    386\u001b[0m     \u001b[39m# NOTE: everything is left uninitialized; presumably the model will\u001b[39;00m\n\u001b[0;32m    387\u001b[0m     \u001b[39m# be initialized in some other way\u001b[39;00m\n\u001b[0;32m    388\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\basel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\models\\tfidfmodel.py:449\u001b[0m, in \u001b[0;36mTfidfModel.initialize\u001b[1;34m(self, corpus)\u001b[0m\n\u001b[0;32m    447\u001b[0m         logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mPROGRESS: processing document #\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m\"\u001b[39m, docno)\n\u001b[0;32m    448\u001b[0m     numnnz \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(bow)\n\u001b[1;32m--> 449\u001b[0m     \u001b[39mfor\u001b[39;00m termid, _ \u001b[39min\u001b[39;00m bow:\n\u001b[0;32m    450\u001b[0m         dfs[termid] \u001b[39m=\u001b[39m dfs\u001b[39m.\u001b[39mget(termid, \u001b[39m0\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    451\u001b[0m \u001b[39m# keep some stats about the training corpus\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from summa.summarizer import summarize as lexrank_summarize\n",
    "from gensim.models import TfidfModel, LsiModel\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "data = [\"This is the first document.\", \"This is the second document.\", \"And this is the third one.\", \"Is this the first document?\"]\n",
    "target = [\"summary 1\", \"summary 2\", \"summary 3\", \"summary 4\"]\n",
    "\n",
    "# Tokenize the data into a corpus of documents\n",
    "corpus = [doc.split() for doc in data]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(corpus, target, test_size=0.2)\n",
    "\n",
    "# Define the summarization models\n",
    "lexrank_model = lambda text: lexrank_summarize(text)\n",
    "lsa_model = TfidfModel(corpus)\n",
    "corpus_tfidf = lsa_model[corpus]\n",
    "dictionary = corpora.Dictionary(corpus)\n",
    "corpus_tfidf = lsa_model[corpus]\n",
    "lsa_model = LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2)\n",
    "lsa_model = lambda text: summarize(text, words=30)\n",
    "\n",
    "# Define the vectorizer for LSA\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Define the voting classifier\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "    (\"textrank\", textrank_model),\n",
    "    (\"lexrank\", lexrank_model),\n",
    "    (\"lsa\", lsa_model)\n",
    "], voting=\"hard\")\n",
    "\n",
    "# Fit the voting classifier on the training data\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the testing data\n",
    "y_pred = voting_classifier.predict(X_test)\n",
    "\n",
    "# Compute the accuracy of the predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
