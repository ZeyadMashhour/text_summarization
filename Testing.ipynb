{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imported_libraries import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Articles</th>\n",
       "      <th>Summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...</td>\n",
       "      <td>TimeWarner said fourth quarter sales rose 2% t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...</td>\n",
       "      <td>The dollar has hit its highest level against t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...</td>\n",
       "      <td>Yukos' owner Menatep Group says it will ask Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\r\\n\\r\\nBriti...</td>\n",
       "      <td>Rod Eddington, BA's chief executive, said the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare...</td>\n",
       "      <td>Pernod has reduced the debt it took on to fund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Japan narrowly escapes recession\\r\\n\\r\\nJapan'...</td>\n",
       "      <td>On an annual basis, the data suggests annual g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jobs growth still slow in the US\\r\\n\\r\\nThe US...</td>\n",
       "      <td>The job gains mean that President Bush can cel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>India calls for fair trade rules\\r\\n\\r\\nIndia,...</td>\n",
       "      <td>At a conference on developing enterprise hoste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ethiopia's crop production up 24%\\r\\n\\r\\nEthio...</td>\n",
       "      <td>In 2003, crop production totalled 11.49 millio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Court rejects $280bn tobacco case\\r\\n\\r\\nA US ...</td>\n",
       "      <td>A US government claim accusing the country's b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Articles  \\\n",
       "0  Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...   \n",
       "1  Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...   \n",
       "2  Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...   \n",
       "3  High fuel prices hit BA's profits\\r\\n\\r\\nBriti...   \n",
       "4  Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare...   \n",
       "5  Japan narrowly escapes recession\\r\\n\\r\\nJapan'...   \n",
       "6  Jobs growth still slow in the US\\r\\n\\r\\nThe US...   \n",
       "7  India calls for fair trade rules\\r\\n\\r\\nIndia,...   \n",
       "8  Ethiopia's crop production up 24%\\r\\n\\r\\nEthio...   \n",
       "9  Court rejects $280bn tobacco case\\r\\n\\r\\nA US ...   \n",
       "\n",
       "                                           Summaries  \n",
       "0  TimeWarner said fourth quarter sales rose 2% t...  \n",
       "1  The dollar has hit its highest level against t...  \n",
       "2  Yukos' owner Menatep Group says it will ask Ro...  \n",
       "3  Rod Eddington, BA's chief executive, said the ...  \n",
       "4  Pernod has reduced the debt it took on to fund...  \n",
       "5  On an annual basis, the data suggests annual g...  \n",
       "6  The job gains mean that President Bush can cel...  \n",
       "7  At a conference on developing enterprise hoste...  \n",
       "8  In 2003, crop production totalled 11.49 millio...  \n",
       "9  A US government claim accusing the country's b...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"BBC_Dataset.csv\")\n",
    "df=df.iloc[:,1:]#remove first column(unnamed col)\n",
    "df.dropna(inplace=True)\n",
    "columns_titles = [\"Articles\",\"Summaries\"]\n",
    "df=df.reindex(columns=columns_titles)\n",
    "mini_df = df[:10]\n",
    "mini_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"dataset.csv\")\n",
    "# df=df.iloc[:,1:]#remove first column(unnamed col)\n",
    "# df.dropna(inplace=True)\n",
    "# columns_titles = [\"original\",\"summary\"]\n",
    "# df=df.reindex(columns=columns_titles)\n",
    "# mini_df = df[:10]\n",
    "# mini_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Preprocessing\"\"\"                            #(lemm,stopwords)\n",
    "sentences, filtered_sentences = process_df(mini_df,True,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.\\r\\n\\r\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'its profit be buoy by one - off gain which offset a profit dip at warner bros and less user for aol'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sentences[0][3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 3342.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent_socres [128, 106, 51, 78, 55, 46, 79, 106, 137, 116, 65, 166, 95, 144, 98, 89, 73, 238, 69]\n",
      "sorted [17 11 13  8  0  9  7  1 14 12 15  6  3 16 18 10  4  2  5]\n",
      "sent_socres [149, 117, 74, 60, 169, 151, 101, 52, 126, 130, 72, 156, 101, 163, 115]\n",
      "sorted [ 4 13 11  5  0  9  8  1 14 12  6  2 10  3  7]\n",
      "sent_socres [27, 101, 98, 84, 60, 64, 154, 159, 38, 99, 100, 91, 125]\n",
      "sorted [ 7  6 12  1 10  9  2 11  3  5  4  8  0]\n",
      "sent_socres [190, 97, 81, 87, 112, 227, 162, 49, 136, 51, 54, 85, 150, 90, 93, 113, 35]\n",
      "sorted [ 5  0  6 12  8 15  4  1 14 13  3 11  2 10  9  7 16]\n",
      "sent_socres [137, 119, 66, 56, 105, 51, 112, 94, 80, 147, 90, 122]\n",
      "sorted [ 9  0 11  1  6  4  7 10  8  2  3  5]\n",
      "sent_socres [113, 82, 107, 76, 60, 143, 120, 100, 118]\n",
      "sorted [5 6 8 0 2 7 1 3 4]\n",
      "sent_socres [127, 60, 62, 84, 117, 103, 53, 96, 83, 89, 109, 121, 103, 54, 0]\n",
      "sorted [ 0 11  4 10 12  5  7  9  3  8  2  1 13  6 14]\n",
      "sent_socres [127, 103, 78, 58, 158, 68, 103, 157, 93, 117, 127, 38, 44, 149, 44]\n",
      "sorted [ 4  7 13 10  0  9  6  1  8  2  5  3 14 12 11]\n",
      "sent_socres [136, 119, 76, 62, 64, 170, 67, 76, 78, 174, 79, 57]\n",
      "sorted [ 9  5  0  1 10  8  7  2  6  4  3 11]\n",
      "sent_socres [134, 81, 82, 93, 192, 119, 145, 81, 103, 83]\n",
      "sorted [4 6 0 5 8 3 9 2 7 1]\n",
      "                              luhn_algorithm summary\n",
      "0  The company said it was unable to estimate the...\n",
      "1  On Friday, Federal Reserve chairman Mr Greensp...\n",
      "2  Menatep Group's managing director Tim Osborne ...\n",
      "3  Yet aviation analyst Mike Powell of Dresdner K...\n",
      "4  Allied Domecq's big names include Malibu rum, ...\n",
      "5  \"I maintain the view that Japan's economy rema...\n",
      "6  Jobs growth still slow in the US\\r\\n\\r\\nThe US...\n",
      "7  Palaniappan Chidambaram, India's finance minis...\n",
      "8  \"Local purchase of cereals for food assistance...\n",
      "9  In its case, the government claimed tobacco fi...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Parameters are sentences,filtered_sentences ,summary_algorithm, size = 2(default value)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "lunh_algorithm_summary = summarize_with(list_of_articles= sentences, list_of_filtered_articles= filtered_sentences, summary_algorithm= luhn_algorithm, size=5) \n",
    "print(lunh_algorithm_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.23s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1_fmeasure</th>\n",
       "      <th>rouge1_precision</th>\n",
       "      <th>rouge1_recall</th>\n",
       "      <th>rouge2_fmeasure</th>\n",
       "      <th>rouge2_precision</th>\n",
       "      <th>rouge2_recall</th>\n",
       "      <th>rougeL_fmeasure</th>\n",
       "      <th>rougeL_precision</th>\n",
       "      <th>rougeL_recall</th>\n",
       "      <th>rougeLsum_fmeasure</th>\n",
       "      <th>rougeLsum_precision</th>\n",
       "      <th>rougeLsum_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(0.4230)</td>\n",
       "      <td>tensor(0.3933)</td>\n",
       "      <td>tensor(0.4575)</td>\n",
       "      <td>tensor(0.1702)</td>\n",
       "      <td>tensor(0.1582)</td>\n",
       "      <td>tensor(0.1842)</td>\n",
       "      <td>tensor(0.1934)</td>\n",
       "      <td>tensor(0.1798)</td>\n",
       "      <td>tensor(0.2092)</td>\n",
       "      <td>tensor(0.2417)</td>\n",
       "      <td>tensor(0.2247)</td>\n",
       "      <td>tensor(0.2614)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(0.6927)</td>\n",
       "      <td>tensor(0.6596)</td>\n",
       "      <td>tensor(0.7294)</td>\n",
       "      <td>tensor(0.5955)</td>\n",
       "      <td>tensor(0.5668)</td>\n",
       "      <td>tensor(0.6272)</td>\n",
       "      <td>tensor(0.3296)</td>\n",
       "      <td>tensor(0.3138)</td>\n",
       "      <td>tensor(0.3471)</td>\n",
       "      <td>tensor(0.6648)</td>\n",
       "      <td>tensor(0.6330)</td>\n",
       "      <td>tensor(0.7000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(0.5055)</td>\n",
       "      <td>tensor(0.4825)</td>\n",
       "      <td>tensor(0.5308)</td>\n",
       "      <td>tensor(0.2952)</td>\n",
       "      <td>tensor(0.2817)</td>\n",
       "      <td>tensor(0.3101)</td>\n",
       "      <td>tensor(0.3223)</td>\n",
       "      <td>tensor(0.3077)</td>\n",
       "      <td>tensor(0.3385)</td>\n",
       "      <td>tensor(0.4396)</td>\n",
       "      <td>tensor(0.4196)</td>\n",
       "      <td>tensor(0.4615)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(0.7654)</td>\n",
       "      <td>tensor(0.7828)</td>\n",
       "      <td>tensor(0.7488)</td>\n",
       "      <td>tensor(0.6600)</td>\n",
       "      <td>tensor(0.6751)</td>\n",
       "      <td>tensor(0.6456)</td>\n",
       "      <td>tensor(0.3852)</td>\n",
       "      <td>tensor(0.3939)</td>\n",
       "      <td>tensor(0.3768)</td>\n",
       "      <td>tensor(0.7457)</td>\n",
       "      <td>tensor(0.7626)</td>\n",
       "      <td>tensor(0.7295)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(0.6966)</td>\n",
       "      <td>tensor(0.6200)</td>\n",
       "      <td>tensor(0.7949)</td>\n",
       "      <td>tensor(0.6566)</td>\n",
       "      <td>tensor(0.5839)</td>\n",
       "      <td>tensor(0.7500)</td>\n",
       "      <td>tensor(0.5019)</td>\n",
       "      <td>tensor(0.4467)</td>\n",
       "      <td>tensor(0.5726)</td>\n",
       "      <td>tensor(0.6667)</td>\n",
       "      <td>tensor(0.5933)</td>\n",
       "      <td>tensor(0.7607)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tensor(0.5354)</td>\n",
       "      <td>tensor(0.4274)</td>\n",
       "      <td>tensor(0.7162)</td>\n",
       "      <td>tensor(0.4490)</td>\n",
       "      <td>tensor(0.3577)</td>\n",
       "      <td>tensor(0.6027)</td>\n",
       "      <td>tensor(0.2828)</td>\n",
       "      <td>tensor(0.2258)</td>\n",
       "      <td>tensor(0.3784)</td>\n",
       "      <td>tensor(0.4747)</td>\n",
       "      <td>tensor(0.3790)</td>\n",
       "      <td>tensor(0.6351)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tensor(0.6642)</td>\n",
       "      <td>tensor(0.6842)</td>\n",
       "      <td>tensor(0.6454)</td>\n",
       "      <td>tensor(0.5441)</td>\n",
       "      <td>tensor(0.5606)</td>\n",
       "      <td>tensor(0.5286)</td>\n",
       "      <td>tensor(0.3942)</td>\n",
       "      <td>tensor(0.4060)</td>\n",
       "      <td>tensor(0.3830)</td>\n",
       "      <td>tensor(0.6277)</td>\n",
       "      <td>tensor(0.6466)</td>\n",
       "      <td>tensor(0.6099)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tensor(0.7121)</td>\n",
       "      <td>tensor(0.7372)</td>\n",
       "      <td>tensor(0.6886)</td>\n",
       "      <td>tensor(0.5919)</td>\n",
       "      <td>tensor(0.6129)</td>\n",
       "      <td>tensor(0.5723)</td>\n",
       "      <td>tensor(0.4768)</td>\n",
       "      <td>tensor(0.4936)</td>\n",
       "      <td>tensor(0.4611)</td>\n",
       "      <td>tensor(0.4768)</td>\n",
       "      <td>tensor(0.4936)</td>\n",
       "      <td>tensor(0.4611)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tensor(0.6154)</td>\n",
       "      <td>tensor(0.5315)</td>\n",
       "      <td>tensor(0.7308)</td>\n",
       "      <td>tensor(0.4816)</td>\n",
       "      <td>tensor(0.4155)</td>\n",
       "      <td>tensor(0.5728)</td>\n",
       "      <td>tensor(0.3158)</td>\n",
       "      <td>tensor(0.2727)</td>\n",
       "      <td>tensor(0.3750)</td>\n",
       "      <td>tensor(0.5344)</td>\n",
       "      <td>tensor(0.4615)</td>\n",
       "      <td>tensor(0.6346)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tensor(0.5966)</td>\n",
       "      <td>tensor(0.4965)</td>\n",
       "      <td>tensor(0.7474)</td>\n",
       "      <td>tensor(0.4915)</td>\n",
       "      <td>tensor(0.4085)</td>\n",
       "      <td>tensor(0.6170)</td>\n",
       "      <td>tensor(0.3361)</td>\n",
       "      <td>tensor(0.2797)</td>\n",
       "      <td>tensor(0.4211)</td>\n",
       "      <td>tensor(0.5378)</td>\n",
       "      <td>tensor(0.4476)</td>\n",
       "      <td>tensor(0.6737)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rouge1_fmeasure rouge1_precision   rouge1_recall rouge2_fmeasure  \\\n",
       "0  tensor(0.4230)   tensor(0.3933)  tensor(0.4575)  tensor(0.1702)   \n",
       "1  tensor(0.6927)   tensor(0.6596)  tensor(0.7294)  tensor(0.5955)   \n",
       "2  tensor(0.5055)   tensor(0.4825)  tensor(0.5308)  tensor(0.2952)   \n",
       "3  tensor(0.7654)   tensor(0.7828)  tensor(0.7488)  tensor(0.6600)   \n",
       "4  tensor(0.6966)   tensor(0.6200)  tensor(0.7949)  tensor(0.6566)   \n",
       "5  tensor(0.5354)   tensor(0.4274)  tensor(0.7162)  tensor(0.4490)   \n",
       "6  tensor(0.6642)   tensor(0.6842)  tensor(0.6454)  tensor(0.5441)   \n",
       "7  tensor(0.7121)   tensor(0.7372)  tensor(0.6886)  tensor(0.5919)   \n",
       "8  tensor(0.6154)   tensor(0.5315)  tensor(0.7308)  tensor(0.4816)   \n",
       "9  tensor(0.5966)   tensor(0.4965)  tensor(0.7474)  tensor(0.4915)   \n",
       "\n",
       "  rouge2_precision   rouge2_recall rougeL_fmeasure rougeL_precision  \\\n",
       "0   tensor(0.1582)  tensor(0.1842)  tensor(0.1934)   tensor(0.1798)   \n",
       "1   tensor(0.5668)  tensor(0.6272)  tensor(0.3296)   tensor(0.3138)   \n",
       "2   tensor(0.2817)  tensor(0.3101)  tensor(0.3223)   tensor(0.3077)   \n",
       "3   tensor(0.6751)  tensor(0.6456)  tensor(0.3852)   tensor(0.3939)   \n",
       "4   tensor(0.5839)  tensor(0.7500)  tensor(0.5019)   tensor(0.4467)   \n",
       "5   tensor(0.3577)  tensor(0.6027)  tensor(0.2828)   tensor(0.2258)   \n",
       "6   tensor(0.5606)  tensor(0.5286)  tensor(0.3942)   tensor(0.4060)   \n",
       "7   tensor(0.6129)  tensor(0.5723)  tensor(0.4768)   tensor(0.4936)   \n",
       "8   tensor(0.4155)  tensor(0.5728)  tensor(0.3158)   tensor(0.2727)   \n",
       "9   tensor(0.4085)  tensor(0.6170)  tensor(0.3361)   tensor(0.2797)   \n",
       "\n",
       "    rougeL_recall rougeLsum_fmeasure rougeLsum_precision rougeLsum_recall  \n",
       "0  tensor(0.2092)     tensor(0.2417)      tensor(0.2247)   tensor(0.2614)  \n",
       "1  tensor(0.3471)     tensor(0.6648)      tensor(0.6330)   tensor(0.7000)  \n",
       "2  tensor(0.3385)     tensor(0.4396)      tensor(0.4196)   tensor(0.4615)  \n",
       "3  tensor(0.3768)     tensor(0.7457)      tensor(0.7626)   tensor(0.7295)  \n",
       "4  tensor(0.5726)     tensor(0.6667)      tensor(0.5933)   tensor(0.7607)  \n",
       "5  tensor(0.3784)     tensor(0.4747)      tensor(0.3790)   tensor(0.6351)  \n",
       "6  tensor(0.3830)     tensor(0.6277)      tensor(0.6466)   tensor(0.6099)  \n",
       "7  tensor(0.4611)     tensor(0.4768)      tensor(0.4936)   tensor(0.4611)  \n",
       "8  tensor(0.3750)     tensor(0.5344)      tensor(0.4615)   tensor(0.6346)  \n",
       "9  tensor(0.4211)     tensor(0.5378)      tensor(0.4476)   tensor(0.6737)  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Parameters are dataframe of original summary and dataframe of system summary\n",
    "NOTE system summary is calculated in the cell above\n",
    "\"\"\"\n",
    "rouge_scores_df(df=mini_df, algorithm_summary_df=lunh_algorithm_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# horizontal_concat_df = pd.concat(\n",
    "#     [\n",
    "#         mini_df,\n",
    "#         luhn,\n",
    "#         lsa,\n",
    "#         text_matching,\n",
    "#         LexRank\n",
    "#     ],\n",
    "#     axis=1,\n",
    "# )\n",
    "# #horizontal_concat_df[horizontal_concat_df.isnull().any(axis=1)]\n",
    "# horizontal_concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "480c14cd519d4cac626ed4e2ff26eb76a48d8461070c1f960eb23b2ab109b24d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
