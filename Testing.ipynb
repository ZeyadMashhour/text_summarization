{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.text.rouge import ROUGEScore\n",
    "rouge = ROUGEScore()\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summarization_algorithm import * \n",
    "from preprocessing_algorithms import*\n",
    "from efficiency_scores import *\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Daman and Diu administration on Wednesday ...</td>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From her special numbers to TV?appearances, Bo...</td>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hotels in Mumbai and other Indian cities are t...</td>\n",
       "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An alleged suspect in a kidnapping case was fo...</td>\n",
       "      <td>A 32-year-old man on Wednesday was found hangi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4510</th>\n",
       "      <td>Mumbai, Feb 23 (PTI) Fruit juice concentrate m...</td>\n",
       "      <td>Fruit juice concentrate maker Rasna is eyeing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4511</th>\n",
       "      <td>Former cricketer Sachin Tendulkar was spotted ...</td>\n",
       "      <td>Former Indian cricketer Sachin Tendulkar atten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4512</th>\n",
       "      <td>Aamir Khan, whose last film Dangal told the st...</td>\n",
       "      <td>Aamir Khan, while talking about reality shows ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4513</th>\n",
       "      <td>Maharahstra Power Minister Chandrashekhar Bawa...</td>\n",
       "      <td>The Maharashtra government has initiated an in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4514</th>\n",
       "      <td>More than half of the languages spoken by Indi...</td>\n",
       "      <td>At least 400 languages or more than half langu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4396 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               original  \\\n",
       "0     The Daman and Diu administration on Wednesday ...   \n",
       "1     From her special numbers to TV?appearances, Bo...   \n",
       "2     The Indira Gandhi Institute of Medical Science...   \n",
       "3     Hotels in Mumbai and other Indian cities are t...   \n",
       "4     An alleged suspect in a kidnapping case was fo...   \n",
       "...                                                 ...   \n",
       "4510  Mumbai, Feb 23 (PTI) Fruit juice concentrate m...   \n",
       "4511  Former cricketer Sachin Tendulkar was spotted ...   \n",
       "4512  Aamir Khan, whose last film Dangal told the st...   \n",
       "4513  Maharahstra Power Minister Chandrashekhar Bawa...   \n",
       "4514  More than half of the languages spoken by Indi...   \n",
       "\n",
       "                                                summary  \n",
       "0     The Administration of Union Territory Daman an...  \n",
       "1     Malaika Arora slammed an Instagram user who tr...  \n",
       "2     The Indira Gandhi Institute of Medical Science...  \n",
       "3     Hotels in Maharashtra will train their staff t...  \n",
       "4     A 32-year-old man on Wednesday was found hangi...  \n",
       "...                                                 ...  \n",
       "4510  Fruit juice concentrate maker Rasna is eyeing ...  \n",
       "4511  Former Indian cricketer Sachin Tendulkar atten...  \n",
       "4512  Aamir Khan, while talking about reality shows ...  \n",
       "4513  The Maharashtra government has initiated an in...  \n",
       "4514  At least 400 languages or more than half langu...  \n",
       "\n",
       "[4396 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset.csv\")\n",
    "df=df.iloc[:,1:]#remove first column(unnamed col)\n",
    "df.dropna(inplace=True)\n",
    "columns_titles = [\"original\",\"summary\"]\n",
    "df=df.reindex(columns=columns_titles)\n",
    "mini_df = df\n",
    "mini_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"Preprocessing\"\"\"\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m sentences, filtered_sentences \u001b[39m=\u001b[39m process_df(mini_df)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(sentences)\n",
      "File \u001b[1;32mf:\\PycharmProjects\\NLP\\text_summarization\\preprocessing_algorithms.py:59\u001b[0m, in \u001b[0;36mprocess_df\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     57\u001b[0m sentences,filtered_sentences \u001b[39m=\u001b[39m[],[] \n\u001b[0;32m     58\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(rows):\n\u001b[1;32m---> 59\u001b[0m     articles_sentence , filtered_article \u001b[39m=\u001b[39m preprocessing_text_with_spacy(df\u001b[39m.\u001b[39;49miloc[row,\u001b[39m0\u001b[39;49m])\n\u001b[0;32m     60\u001b[0m     sentences\u001b[39m.\u001b[39mappend(articles_sentence)\n\u001b[0;32m     61\u001b[0m     filtered_sentences\u001b[39m.\u001b[39mappend(filtered_article)\n",
      "File \u001b[1;32mf:\\PycharmProjects\\NLP\\text_summarization\\preprocessing_algorithms.py:42\u001b[0m, in \u001b[0;36mpreprocessing_text_with_spacy\u001b[1;34m(text, lemmatization)\u001b[0m\n\u001b[0;32m     39\u001b[0m filtered \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     41\u001b[0m \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m sentences_group:\n\u001b[1;32m---> 42\u001b[0m     sentence_doc \u001b[39m=\u001b[39m nlp(sentence)\n\u001b[0;32m     43\u001b[0m     words_of_sentence \u001b[39m=\u001b[39m [token\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m sentence_doc]\n\u001b[0;32m     45\u001b[0m     \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m sentence_doc:\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\language.py:1011\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1009\u001b[0m     error_handler \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39mget_error_handler()\n\u001b[0;32m   1010\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1011\u001b[0m     doc \u001b[39m=\u001b[39m proc(doc, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcomponent_cfg\u001b[39m.\u001b[39mget(name, {}))  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1013\u001b[0m     \u001b[39m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1014\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE109\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\pipeline\\tok2vec.py:125\u001b[0m, in \u001b[0;36mTok2Vec.predict\u001b[1;34m(self, docs)\u001b[0m\n\u001b[0;32m    123\u001b[0m     width \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mget_dim(\u001b[39m\"\u001b[39m\u001b[39mnO\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    124\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39malloc((\u001b[39m0\u001b[39m, width)) \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m docs]\n\u001b[1;32m--> 125\u001b[0m tokvecs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(docs)\n\u001b[0;32m    126\u001b[0m \u001b[39mreturn\u001b[39;00m tokvecs\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\model.py:315\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X: InT) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OutT:\n\u001b[0;32m    312\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[39m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\layers\\with_array.py:38\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, Xseq, is_train)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mlayers[\u001b[39m0\u001b[39m](Xseq, is_train)\n\u001b[0;32m     37\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _list_forward(model, Xseq, is_train))\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\layers\\with_array.py:73\u001b[0m, in \u001b[0;36m_list_forward\u001b[1;34m(model, Xs, is_train)\u001b[0m\n\u001b[0;32m     71\u001b[0m lengths \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39masarray1i([\u001b[39mlen\u001b[39m(seq) \u001b[39mfor\u001b[39;00m seq \u001b[39min\u001b[39;00m Xs])\n\u001b[0;32m     72\u001b[0m Xf \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mflatten(Xs, pad\u001b[39m=\u001b[39mpad)\n\u001b[1;32m---> 73\u001b[0m Yf, get_dXf \u001b[39m=\u001b[39m layer(Xf, is_train)\n\u001b[0;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackprop\u001b[39m(dYs: ListXd) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ListXd:\n\u001b[0;32m     76\u001b[0m     dYf \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mflatten(dYs, pad\u001b[39m=\u001b[39mpad)\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\layers\\residual.py:41\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[39mreturn\u001b[39;00m d_output \u001b[39m+\u001b[39m dX\n\u001b[1;32m---> 41\u001b[0m Y, backprop_layer \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mlayers[\u001b[39m0\u001b[39;49m](X, is_train)\n\u001b[0;32m     42\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(X, \u001b[39mlist\u001b[39m):\n\u001b[0;32m     43\u001b[0m     \u001b[39mreturn\u001b[39;00m [X[i] \u001b[39m+\u001b[39m Y[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X))], backprop\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "    \u001b[1;31m[... skipping similar frames: Model.__call__ at line 291 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\layers\\maxout.py:53\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     51\u001b[0m W \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mget_param(\u001b[39m\"\u001b[39m\u001b[39mW\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     52\u001b[0m W \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mreshape2f(W, nO \u001b[39m*\u001b[39m nP, nI)\n\u001b[1;32m---> 53\u001b[0m Y \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mgemm(X, W, trans2\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     54\u001b[0m Y \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mreshape1f(b, nO \u001b[39m*\u001b[39m nP)\n\u001b[0;32m     55\u001b[0m Z \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mreshape3f(Y, Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], nO, nP)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"Preprocessing\"\"\"\n",
    "sentences, filtered_sentences = process_df(mini_df)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               luhn_algorithm summary\n",
      "0   The Daman and Diu administration on Wednesday ...\n",
      "1   A post shared by Malaika Arora Khan (@malaikaa...\n",
      "2   In its response, the management of the autonom...\n",
      "3   Human trafficking is the world's fastest growi...\n",
      "4   A native of Kasganj in UP, Kumar was unmarried...\n",
      "..                                                ...\n",
      "95  Facing pressure from President Donald Trump to...\n",
      "96  The Allahabad High Court today said it would h...\n",
      "97  Motorman Mahendra Prasad called up the railway...\n",
      "98  Following strict orders of the Karnataka Power...\n",
      "99  Rather than look at how greenhouse gases will ...\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Parameters are sentences,filtered_sentences ,summary_algorithm, size = 2(default value)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "lunh_algorithm_summary = summarize_with(list_of_articles= sentences, list_of_filtered_articles= filtered_sentences, summary_algorithm= luhn_algorithm, size=5) \n",
    "print(lunh_algorithm_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1_fmeasure</th>\n",
       "      <th>rouge1_precision</th>\n",
       "      <th>rouge1_recall</th>\n",
       "      <th>rouge2_fmeasure</th>\n",
       "      <th>rouge2_precision</th>\n",
       "      <th>rouge2_recall</th>\n",
       "      <th>rougeL_fmeasure</th>\n",
       "      <th>rougeL_precision</th>\n",
       "      <th>rougeL_recall</th>\n",
       "      <th>rougeLsum_fmeasure</th>\n",
       "      <th>rougeLsum_precision</th>\n",
       "      <th>rougeLsum_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(0.4711)</td>\n",
       "      <td>tensor(0.3212)</td>\n",
       "      <td>tensor(0.8833)</td>\n",
       "      <td>tensor(0.2691)</td>\n",
       "      <td>tensor(0.1829)</td>\n",
       "      <td>tensor(0.5085)</td>\n",
       "      <td>tensor(0.2400)</td>\n",
       "      <td>tensor(0.1636)</td>\n",
       "      <td>tensor(0.4500)</td>\n",
       "      <td>tensor(0.2933)</td>\n",
       "      <td>tensor(0.2000)</td>\n",
       "      <td>tensor(0.5500)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(0.1645)</td>\n",
       "      <td>tensor(0.1131)</td>\n",
       "      <td>tensor(0.3016)</td>\n",
       "      <td>tensor(0.0262)</td>\n",
       "      <td>tensor(0.0180)</td>\n",
       "      <td>tensor(0.0484)</td>\n",
       "      <td>tensor(0.1212)</td>\n",
       "      <td>tensor(0.0833)</td>\n",
       "      <td>tensor(0.2222)</td>\n",
       "      <td>tensor(0.1385)</td>\n",
       "      <td>tensor(0.0952)</td>\n",
       "      <td>tensor(0.2540)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(0.3553)</td>\n",
       "      <td>tensor(0.2555)</td>\n",
       "      <td>tensor(0.5833)</td>\n",
       "      <td>tensor(0.2359)</td>\n",
       "      <td>tensor(0.1691)</td>\n",
       "      <td>tensor(0.3898)</td>\n",
       "      <td>tensor(0.2132)</td>\n",
       "      <td>tensor(0.1533)</td>\n",
       "      <td>tensor(0.3500)</td>\n",
       "      <td>tensor(0.2741)</td>\n",
       "      <td>tensor(0.1971)</td>\n",
       "      <td>tensor(0.4500)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(0.1967)</td>\n",
       "      <td>tensor(0.1304)</td>\n",
       "      <td>tensor(0.4000)</td>\n",
       "      <td>tensor(0.0331)</td>\n",
       "      <td>tensor(0.0219)</td>\n",
       "      <td>tensor(0.0678)</td>\n",
       "      <td>tensor(0.1148)</td>\n",
       "      <td>tensor(0.0761)</td>\n",
       "      <td>tensor(0.2333)</td>\n",
       "      <td>tensor(0.1721)</td>\n",
       "      <td>tensor(0.1141)</td>\n",
       "      <td>tensor(0.3500)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(0.4245)</td>\n",
       "      <td>tensor(0.2842)</td>\n",
       "      <td>tensor(0.8387)</td>\n",
       "      <td>tensor(0.1893)</td>\n",
       "      <td>tensor(0.1264)</td>\n",
       "      <td>tensor(0.3770)</td>\n",
       "      <td>tensor(0.2367)</td>\n",
       "      <td>tensor(0.1585)</td>\n",
       "      <td>tensor(0.4677)</td>\n",
       "      <td>tensor(0.3510)</td>\n",
       "      <td>tensor(0.2350)</td>\n",
       "      <td>tensor(0.6935)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>tensor(0.3566)</td>\n",
       "      <td>tensor(0.2277)</td>\n",
       "      <td>tensor(0.8214)</td>\n",
       "      <td>tensor(0.1875)</td>\n",
       "      <td>tensor(0.1194)</td>\n",
       "      <td>tensor(0.4364)</td>\n",
       "      <td>tensor(0.2791)</td>\n",
       "      <td>tensor(0.1782)</td>\n",
       "      <td>tensor(0.6429)</td>\n",
       "      <td>tensor(0.3023)</td>\n",
       "      <td>tensor(0.1931)</td>\n",
       "      <td>tensor(0.6964)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>tensor(0.6188)</td>\n",
       "      <td>tensor(0.4553)</td>\n",
       "      <td>tensor(0.9655)</td>\n",
       "      <td>tensor(0.5028)</td>\n",
       "      <td>tensor(0.3689)</td>\n",
       "      <td>tensor(0.7895)</td>\n",
       "      <td>tensor(0.5635)</td>\n",
       "      <td>tensor(0.4146)</td>\n",
       "      <td>tensor(0.8793)</td>\n",
       "      <td>tensor(0.5746)</td>\n",
       "      <td>tensor(0.4228)</td>\n",
       "      <td>tensor(0.8966)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>tensor(0.3069)</td>\n",
       "      <td>tensor(0.2246)</td>\n",
       "      <td>tensor(0.4844)</td>\n",
       "      <td>tensor(0.0800)</td>\n",
       "      <td>tensor(0.0584)</td>\n",
       "      <td>tensor(0.1270)</td>\n",
       "      <td>tensor(0.1782)</td>\n",
       "      <td>tensor(0.1304)</td>\n",
       "      <td>tensor(0.2812)</td>\n",
       "      <td>tensor(0.1881)</td>\n",
       "      <td>tensor(0.1377)</td>\n",
       "      <td>tensor(0.2969)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>tensor(0.3765)</td>\n",
       "      <td>tensor(0.2909)</td>\n",
       "      <td>tensor(0.5333)</td>\n",
       "      <td>tensor(0.1786)</td>\n",
       "      <td>tensor(0.1376)</td>\n",
       "      <td>tensor(0.2542)</td>\n",
       "      <td>tensor(0.2353)</td>\n",
       "      <td>tensor(0.1818)</td>\n",
       "      <td>tensor(0.3333)</td>\n",
       "      <td>tensor(0.2824)</td>\n",
       "      <td>tensor(0.2182)</td>\n",
       "      <td>tensor(0.4000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>tensor(0.2327)</td>\n",
       "      <td>tensor(0.1517)</td>\n",
       "      <td>tensor(0.5000)</td>\n",
       "      <td>tensor(0.0220)</td>\n",
       "      <td>tensor(0.0143)</td>\n",
       "      <td>tensor(0.0476)</td>\n",
       "      <td>tensor(0.0945)</td>\n",
       "      <td>tensor(0.0616)</td>\n",
       "      <td>tensor(0.2031)</td>\n",
       "      <td>tensor(0.1745)</td>\n",
       "      <td>tensor(0.1137)</td>\n",
       "      <td>tensor(0.3750)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rouge1_fmeasure rouge1_precision   rouge1_recall rouge2_fmeasure  \\\n",
       "0   tensor(0.4711)   tensor(0.3212)  tensor(0.8833)  tensor(0.2691)   \n",
       "1   tensor(0.1645)   tensor(0.1131)  tensor(0.3016)  tensor(0.0262)   \n",
       "2   tensor(0.3553)   tensor(0.2555)  tensor(0.5833)  tensor(0.2359)   \n",
       "3   tensor(0.1967)   tensor(0.1304)  tensor(0.4000)  tensor(0.0331)   \n",
       "4   tensor(0.4245)   tensor(0.2842)  tensor(0.8387)  tensor(0.1893)   \n",
       "..             ...              ...             ...             ...   \n",
       "95  tensor(0.3566)   tensor(0.2277)  tensor(0.8214)  tensor(0.1875)   \n",
       "96  tensor(0.6188)   tensor(0.4553)  tensor(0.9655)  tensor(0.5028)   \n",
       "97  tensor(0.3069)   tensor(0.2246)  tensor(0.4844)  tensor(0.0800)   \n",
       "98  tensor(0.3765)   tensor(0.2909)  tensor(0.5333)  tensor(0.1786)   \n",
       "99  tensor(0.2327)   tensor(0.1517)  tensor(0.5000)  tensor(0.0220)   \n",
       "\n",
       "   rouge2_precision   rouge2_recall rougeL_fmeasure rougeL_precision  \\\n",
       "0    tensor(0.1829)  tensor(0.5085)  tensor(0.2400)   tensor(0.1636)   \n",
       "1    tensor(0.0180)  tensor(0.0484)  tensor(0.1212)   tensor(0.0833)   \n",
       "2    tensor(0.1691)  tensor(0.3898)  tensor(0.2132)   tensor(0.1533)   \n",
       "3    tensor(0.0219)  tensor(0.0678)  tensor(0.1148)   tensor(0.0761)   \n",
       "4    tensor(0.1264)  tensor(0.3770)  tensor(0.2367)   tensor(0.1585)   \n",
       "..              ...             ...             ...              ...   \n",
       "95   tensor(0.1194)  tensor(0.4364)  tensor(0.2791)   tensor(0.1782)   \n",
       "96   tensor(0.3689)  tensor(0.7895)  tensor(0.5635)   tensor(0.4146)   \n",
       "97   tensor(0.0584)  tensor(0.1270)  tensor(0.1782)   tensor(0.1304)   \n",
       "98   tensor(0.1376)  tensor(0.2542)  tensor(0.2353)   tensor(0.1818)   \n",
       "99   tensor(0.0143)  tensor(0.0476)  tensor(0.0945)   tensor(0.0616)   \n",
       "\n",
       "     rougeL_recall rougeLsum_fmeasure rougeLsum_precision rougeLsum_recall  \n",
       "0   tensor(0.4500)     tensor(0.2933)      tensor(0.2000)   tensor(0.5500)  \n",
       "1   tensor(0.2222)     tensor(0.1385)      tensor(0.0952)   tensor(0.2540)  \n",
       "2   tensor(0.3500)     tensor(0.2741)      tensor(0.1971)   tensor(0.4500)  \n",
       "3   tensor(0.2333)     tensor(0.1721)      tensor(0.1141)   tensor(0.3500)  \n",
       "4   tensor(0.4677)     tensor(0.3510)      tensor(0.2350)   tensor(0.6935)  \n",
       "..             ...                ...                 ...              ...  \n",
       "95  tensor(0.6429)     tensor(0.3023)      tensor(0.1931)   tensor(0.6964)  \n",
       "96  tensor(0.8793)     tensor(0.5746)      tensor(0.4228)   tensor(0.8966)  \n",
       "97  tensor(0.2812)     tensor(0.1881)      tensor(0.1377)   tensor(0.2969)  \n",
       "98  tensor(0.3333)     tensor(0.2824)      tensor(0.2182)   tensor(0.4000)  \n",
       "99  tensor(0.2031)     tensor(0.1745)      tensor(0.1137)   tensor(0.3750)  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Parameters are dataframe of original summary and dataframe of system summary\n",
    "NOTE system summary is calculated in the cell above\n",
    "\"\"\"\n",
    "rouge_scores_df(df=mini_df, algorithm_summary_df=lunh_algorithm_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# horizontal_concat_df = pd.concat(\n",
    "#     [\n",
    "#         mini_df,\n",
    "#         luhn,\n",
    "#         lsa,\n",
    "#         text_matching,\n",
    "#         LexRank\n",
    "#     ],\n",
    "#     axis=1,\n",
    "# )\n",
    "# #horizontal_concat_df[horizontal_concat_df.isnull().any(axis=1)]\n",
    "# horizontal_concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1_fmeasure': tensor(0.4711),\n",
       " 'rouge1_precision': tensor(0.3212),\n",
       " 'rouge1_recall': tensor(0.8833),\n",
       " 'rouge2_fmeasure': tensor(0.2691),\n",
       " 'rouge2_precision': tensor(0.1829),\n",
       " 'rouge2_recall': tensor(0.5085),\n",
       " 'rougeL_fmeasure': tensor(0.2400),\n",
       " 'rougeL_precision': tensor(0.1636),\n",
       " 'rougeL_recall': tensor(0.4500),\n",
       " 'rougeLsum_fmeasure': tensor(0.2933),\n",
       " 'rougeLsum_precision': tensor(0.2000),\n",
       " 'rougeLsum_recall': tensor(0.5500)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_efficiency(predicted_summary=lunh_algorithm_summary.iloc[0,0], original_summary=mini_df.iloc[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In its response, the management of the autonomous super-specialty health facility had clarified on Wednesday that it was in adherence to the central civil services rules followed by the All India Institute of Medical Sciences in New Delhi.IGIMS medical superintendent Dr Manish Mandal said institute director Dr NR Biswas held a meeting on Thursday morning before directing that the word ?virgin?Earlier, Bihar health minister Mangal Pandey had ended up redefining the very meaning of virginity in his attempts to justify the awkward phrasing of the question in the form.The Indira Gandhi Institute of Medical Sciences (IGIMS) in Patna amended its marital declaration form on Thursday, replacing the word ?Until now, new recruits to the super-specialty medical institute in the state capital were required to declare if they were bachelors, widowers or virgins.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lunh_algorithm_summary.iloc[2,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Indira Gandhi Institute of Medical Sciences (IGIMS) in Patna on Thursday made corrections in its Marital Declaration Form by changing 'Virgin' option to 'Unmarried'. Earlier, Bihar Health Minister defined virgin as being an unmarried woman and did not consider the term objectionable. The institute, however, faced strong backlash for asking new recruits to declare their virginity in the form.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_df.iloc[2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not find the DLL(s) 'msvcp140_1.dll'. TensorFlow requires that these DLLs be installed in a directory that is named in your %PATH% environment variable. You may install these DLLs by downloading \"Microsoft C++ Redistributable for Visual Studio 2015, 2017 and 2019\" for your platform from this URL: https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNum GPUs Available: \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mlen\u001b[39m(tf\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mlist_physical_devices(\u001b[39m'\u001b[39m\u001b[39mGPU\u001b[39m\u001b[39m'\u001b[39m)))\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\__init__.py:36\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtraceback\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[39m# go/tf-wildcard-import\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow \u001b[39mas\u001b[39;00m _pywrap_tensorflow\n\u001b[0;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[39m# Bring in subpackages.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:26\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplatform\u001b[39;00m \u001b[39mimport\u001b[39;00m self_check\n\u001b[0;32m     23\u001b[0m \u001b[39m# TODO(mdan): Cleanup antipattern: import for side effects.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[39m# Perform pre-load sanity checks in order to produce a more actionable error.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m self_check\u001b[39m.\u001b[39;49mpreload_check()\n\u001b[0;32m     28\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m   \u001b[39m# This import is expected to fail if there is an explicit shared object\u001b[39;00m\n\u001b[0;32m     32\u001b[0m   \u001b[39m# dependency (with_framework_lib=true), since we do not need RTLD_GLOBAL.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zeyad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py:50\u001b[0m, in \u001b[0;36mpreload_check\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m         missing\u001b[39m.\u001b[39mappend(dll_name)\n\u001b[0;32m     49\u001b[0m     \u001b[39mif\u001b[39;00m missing:\n\u001b[1;32m---> 50\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m     51\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mCould not find the DLL(s) \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m. TensorFlow requires that these DLLs \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     52\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mbe installed in a directory that is named in your \u001b[39m\u001b[39m%%\u001b[39;00m\u001b[39mPATH\u001b[39m\u001b[39m%%\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39menvironment variable. You may install these DLLs by downloading \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m           \u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMicrosoft C++ Redistributable for Visual Studio 2015, 2017 and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     55\u001b[0m           \u001b[39m'\u001b[39m\u001b[39m2019\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m for your platform from this URL: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     56\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mhttps://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     57\u001b[0m           \u001b[39m%\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m or \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(missing))\n\u001b[0;32m     58\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m   \u001b[39m# Load a library that performs CPU feature guard checking.  Doing this here\u001b[39;00m\n\u001b[0;32m     60\u001b[0m   \u001b[39m# as a preload check makes it more likely that we detect any CPU feature\u001b[39;00m\n\u001b[0;32m     61\u001b[0m   \u001b[39m# incompatibilities before we trigger them (which would typically result in\u001b[39;00m\n\u001b[0;32m     62\u001b[0m   \u001b[39m# SIGILL).\u001b[39;00m\n\u001b[0;32m     63\u001b[0m   \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplatform\u001b[39;00m \u001b[39mimport\u001b[39;00m _pywrap_cpu_feature_guard\n",
      "\u001b[1;31mImportError\u001b[0m: Could not find the DLL(s) 'msvcp140_1.dll'. TensorFlow requires that these DLLs be installed in a directory that is named in your %PATH% environment variable. You may install these DLLs by downloading \"Microsoft C++ Redistributable for Visual Studio 2015, 2017 and 2019\" for your platform from this URL: https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afbd2e3b20535035cb123f2b315173d4c27faa26889583774d241154cf5dbaf6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
