{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be4a7e02-76f1-4fde-bfc1-c5d46afbe828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Big File...\n",
      "Finished Loading Big File.\n"
     ]
    }
   ],
   "source": [
    "%run summarizationBackbone.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab683111-e3fc-4ef1-9337-e7b4abfe199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_algorithms import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7955734c-66f1-4264-8e5b-9f33ea851075",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = pd.read_csv(\"Duc_dataset_first_ref_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9740f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Summarization Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b6cb9aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Column Names\n",
    "articleCol = \"Original Article\"\n",
    "summaryCol = \"Original Summary\"\n",
    "# Documents to be summarized\n",
    "start = 0\n",
    "end = len(ds)\n",
    "# Summarization Percentage [0-1]% if > 1 acts as number of sentences\n",
    "percentage = 5\n",
    "# Pre processing settings\n",
    "lemmatization = True\n",
    "remove_stopwords = True\n",
    "# output file name [MAKE SURE TO CHANGE TO NOT OVERWRITE]\n",
    "outFileName = \"DUC_Weighted_1st_5Sent_lemT_swT.csv\"\n",
    "ppFileName = \"PP_DUC_1st_5Sent_lemT_swT.csv\"\n",
    "ppSpecial = \"#!@!#\"\n",
    "# Weights Settings\n",
    "useWeights = True\n",
    "weights = {\"tm\":0.92,\"luhn\":1,\"lsa\":0.44,\"tr\":0.84,\"lex\":0.88,\"lda\":0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "af32bf3d-e8eb-4b98-9f87-df6e64b11ae4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "Algorithms = [\"Tm\",\"Lex\",\"Luhn\",\"Lsa\",\"Tr\",\"LDA\"]\n",
    "lstCols = get_combinations(Algorithms)\n",
    "cols = [\"Original Article\",\"Original Summary\"] + lstCols\n",
    "df3 = pd.DataFrame(columns = cols)\n",
    "df3.to_csv(outFileName, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c1f36d-3745-4111-9bc1-47a3505b5b22",
   "metadata": {},
   "source": [
    "## Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c908dbc7-2103-43d0-9b9e-2bfd15cef295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [07:24<00:00,  9.08s/it]\n"
     ]
    }
   ],
   "source": [
    "sentences, processed_sentences = process_one_column_df(ds[articleCol],lemmatization,remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7cbed59b-0851-4b57-901f-0e13bf319f04",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "collected = []\n",
    "for i in range(len(sentences)):\n",
    "    collected.append([ds[articleCol][i],ds[summaryCol][i],ppSpecial.join(sentences[i]),ppSpecial.join(processed_sentences[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "93d46318-a2ac-48f4-bfa2-027712766b1c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(collected, columns =[articleCol,summaryCol,\"Sentences\",\"Filtered Sent\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d9226ad9-a2d4-42f7-a4dd-933a50cfef92",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(ppFileName, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c68bcbd5-cc6b-4268-a8e3-cad964049e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(ppFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ad0caeac-ced0-4f9b-9a3a-b1f98163865d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Article</th>\n",
       "      <th>Original Summary</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Filtered Sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nCambodian leader Hun Sen on Friday rejected ...</td>\n",
       "      <td>Prospects were dim for resolution of the polit...</td>\n",
       "      <td>\\nCambodian leader Hun Sen on Friday rejected ...</td>\n",
       "      <td>cambodian leader hun sen friday reject opposit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nHonduras braced for potential catastrophe Tu...</td>\n",
       "      <td>Hurricane Mitch approached Honduras on Oct. 27...</td>\n",
       "      <td>\\nHonduras braced for potential catastrophe Tu...</td>\n",
       "      <td>honduras brace potential catastrophe tuesday h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nCuban President Fidel Castro said Sunday he ...</td>\n",
       "      <td>Britain caused international controversy and C...</td>\n",
       "      <td>\\nCuban President Fidel Castro said Sunday he ...</td>\n",
       "      <td>cuban president fidel castro sunday disagree a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nMUNICH, Germany (AP) _ U.S. prosecutors have...</td>\n",
       "      <td>After the bombing of U.S. embassies in East Af...</td>\n",
       "      <td>\\nMUNICH, Germany (AP) _#!@!#U.S. prosecutors ...</td>\n",
       "      <td>munich germany ap#!@!#prosecutor ask 20 - day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nIn a critical ruling for the North American ...</td>\n",
       "      <td>In a dispute over a new collective bargaining ...</td>\n",
       "      <td>\\nIn a critical ruling for the North American ...</td>\n",
       "      <td>critical rule north american national basketba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Original Article  \\\n",
       "0  \\nCambodian leader Hun Sen on Friday rejected ...   \n",
       "1  \\nHonduras braced for potential catastrophe Tu...   \n",
       "2  \\nCuban President Fidel Castro said Sunday he ...   \n",
       "3  \\nMUNICH, Germany (AP) _ U.S. prosecutors have...   \n",
       "4  \\nIn a critical ruling for the North American ...   \n",
       "\n",
       "                                    Original Summary  \\\n",
       "0  Prospects were dim for resolution of the polit...   \n",
       "1  Hurricane Mitch approached Honduras on Oct. 27...   \n",
       "2  Britain caused international controversy and C...   \n",
       "3  After the bombing of U.S. embassies in East Af...   \n",
       "4  In a dispute over a new collective bargaining ...   \n",
       "\n",
       "                                           Sentences  \\\n",
       "0  \\nCambodian leader Hun Sen on Friday rejected ...   \n",
       "1  \\nHonduras braced for potential catastrophe Tu...   \n",
       "2  \\nCuban President Fidel Castro said Sunday he ...   \n",
       "3  \\nMUNICH, Germany (AP) _#!@!#U.S. prosecutors ...   \n",
       "4  \\nIn a critical ruling for the North American ...   \n",
       "\n",
       "                                       Filtered Sent  \n",
       "0  cambodian leader hun sen friday reject opposit...  \n",
       "1  honduras brace potential catastrophe tuesday h...  \n",
       "2  cuban president fidel castro sunday disagree a...  \n",
       "3  munich germany ap#!@!#prosecutor ask 20 - day ...  \n",
       "4  critical rule north american national basketba...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323f0948-8d29-4414-8ccc-00948524e45a",
   "metadata": {},
   "source": [
    "# one by one docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "05cf673d-6f12-4d33-aeae-ac8e3ee27f61",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def onebyoneSummarization(ds):\n",
    "    summarizedDataset = []\n",
    "    for i in tqdm(range(start,end,1)):\n",
    "        try:\n",
    "            sentences, filtered_sentences = preprocessing_text_with_spacy(ds[articleCol][i],lemmatization,remove_stopwords)\n",
    "            df = buildDF(filtered_sentences, sentences, useWeights, weights)\n",
    "\n",
    "            summarizedRow = {\"Original Article\": ds[articleCol][i],\"Original Summary\": ds[summaryCol][i]}\n",
    "            for key in df.keys():\n",
    "                element = summarizeWith(sentences, df, key, percentage)\n",
    "                summarizedRow[key] = element\n",
    "            pd.DataFrame.from_dict(summarizedRow, orient='index').T.to_csv(outFileName,mode='a',header=False,index=False)\n",
    "            # break\n",
    "        except Exception as e:\n",
    "            print(\"Error\",i, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "27aba8ab-c9fa-4aa1-967d-44ea63445049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, percentage):\n",
    "    try:\n",
    "        sentences, filtered_sentences = preprocessing_text_with_spacy(text,True,False)\n",
    "        df = buildDF(filtered_sentences, sentences)\n",
    "        summarizedRow = {\"Original Article\": ds[articleCol][i]}\n",
    "        for key in df.keys():\n",
    "            element = summarizeWith(sentences, df, key, percentage)\n",
    "            summarizedRow[key] = element\n",
    "        return summarizedRow\n",
    "    except Exception as e:\n",
    "        print(\"Error\",i, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf8bd1c-6fae-4d5d-a003-af9f79323608",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Doc Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fe79e0de-334e-450f-8190-f594085ee726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Big File...\n",
      "Finished Loading Big File.\n"
     ]
    }
   ],
   "source": [
    "%run summarizationBackboneDocLvl.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5e3d3b97-4d18-453c-af11-b3317cd8e030",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstCols = Algorithms\n",
    "data = pd.read_csv(ppFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "aaafd643-72fe-435b-8148-d90a6bbf3f3b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Article</th>\n",
       "      <th>Original Summary</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Filtered Sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nCambodian leader Hun Sen on Friday rejected ...</td>\n",
       "      <td>Prospects were dim for resolution of the polit...</td>\n",
       "      <td>\\nCambodian leader Hun Sen on Friday rejected ...</td>\n",
       "      <td>cambodian leader hun sen friday reject opposit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Original Article  \\\n",
       "0  \\nCambodian leader Hun Sen on Friday rejected ...   \n",
       "\n",
       "                                    Original Summary  \\\n",
       "0  Prospects were dim for resolution of the polit...   \n",
       "\n",
       "                                           Sentences  \\\n",
       "0  \\nCambodian leader Hun Sen on Friday rejected ...   \n",
       "\n",
       "                                       Filtered Sent  \n",
       "0  cambodian leader hun sen friday reject opposit...  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f9914a36-385a-4e41-827b-49789361845b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/49 [00:22<17:43, 22.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Sent      Tm       Lex  \\\n",
      "0    \\nCambodian leader Hun Sen on Friday rejected ...   86.48  0.007123   \n",
      "1    Government and opposition parties have asked \\...  230.00  0.010135   \n",
      "2    Opposition leaders Prince Norodom \\nRanariddh ...   68.08  0.007310   \n",
      "3                     Hun Sen, however, rejected that.    0.00  0.005800   \n",
      "4    ``I would like to make \\nit clear that all mee...   15.64  0.003379   \n",
      "..                                                 ...     ...       ...   \n",
      "183  The deal, which will make Hun Sen \\nprime mini...  125.12  0.010797   \n",
      "184  Sihanouk, recalling \\nprocedures used in a pas...   57.96  0.002221   \n",
      "185  The remaining senators, \\nhe said, should be s...   39.56  0.003788   \n",
      "186  Hun Sen said Monday that the CPP and FUNCINPEC...    1.84  0.007425   \n",
      "187  Other details of the Senate, including how muc...   17.48  0.003327   \n",
      "\n",
      "     Luhn       Lsa        Tr       LDA  \n",
      "0     102 -0.072331  0.004755  0.757687  \n",
      "1     139  0.063839  0.004897  0.771609  \n",
      "2     158 -0.139329  0.004743  0.776242  \n",
      "3      12 -0.069846  0.003592  0.649966  \n",
      "4      59  0.005013  0.004544  0.741619  \n",
      "..    ...       ...       ...       ...  \n",
      "183   213  0.119130  0.004832  0.782158  \n",
      "184    75  0.028747  0.004671  0.751654  \n",
      "185    56  0.090107  0.004536  0.736347  \n",
      "186    68  0.125958  0.004682  0.754618  \n",
      "187    56  0.038536  0.004293  0.721555  \n",
      "\n",
      "[188 rows x 7 columns]\n",
      "Error 0 Column 'Sent' has dtype object, cannot use method 'nlargest' with this dtype\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/49 [00:40<15:42, 20.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Sent     Tm       Lex  Luhn  \\\n",
      "0    \\nHonduras braced for potential catastrophe Tu...  23.92  0.005200   131   \n",
      "1    President Carlos Flores Facusse declared a sta...  30.36  0.004171   102   \n",
      "2    At 0900 GMT Tuesday, Mitch was 95 \\nmiles (152...   8.28  0.005641    60   \n",
      "3    With \\nwinds near 180 mph (289 kph), and even ...  28.52  0.003787    40   \n",
      "4      the highest, most dangerous rating for a storm.  19.32  0.004351    24   \n",
      "..                                                 ...    ...       ...   ...   \n",
      "169  Two British ships that were in the area on \\na...  16.56  0.003780    68   \n",
      "170  ``It's a coincidence that the ships \\nare ther...  10.12  0.004395    85   \n",
      "171  Nicaragua said Friday it will accept Cuba's of...  12.88  0.005621    79   \n",
      "172  Nicaraguan leaders previously had refused \\nCu...   5.52  0.002473    75   \n",
      "173  Nicaragua's leftist Sandinistas, \\nwho maintai...  10.12  0.003475   123   \n",
      "\n",
      "          Lsa        Tr       LDA  \n",
      "0    0.055426  0.005309  0.773064  \n",
      "1    0.034161  0.005145  0.766144  \n",
      "2    0.090736  0.004765  0.753709  \n",
      "3    0.097600  0.004029  0.745473  \n",
      "4    0.026388  0.004744  0.686894  \n",
      "..        ...       ...       ...  \n",
      "169 -0.029158  0.005388  0.752294  \n",
      "170 -0.016361  0.005258  0.752970  \n",
      "171 -0.038586  0.005356  0.756815  \n",
      "172  0.000892  0.004926  0.754041  \n",
      "173  0.001835  0.004566  0.769858  \n",
      "\n",
      "[174 rows x 7 columns]\n",
      "Error 1 Column 'Sent' has dtype object, cannot use method 'nlargest' with this dtype\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/49 [00:51<20:05, 25.66s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m sentences \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentences\u001b[39m\u001b[38;5;124m\"\u001b[39m][i]\u001b[38;5;241m.\u001b[39msplit(ppSpecial)\n\u001b[0;32m      4\u001b[0m filtered_sentences \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiltered Sent\u001b[39m\u001b[38;5;124m\"\u001b[39m][i]\u001b[38;5;241m.\u001b[39msplit(ppSpecial)\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mbuildDF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_sentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43museWeights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n\u001b[0;32m      7\u001b[0m summarizedRow \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal Article\u001b[39m\u001b[38;5;124m\"\u001b[39m: ds[articleCol][i],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal Summary\u001b[39m\u001b[38;5;124m\"\u001b[39m: ds[summaryCol][i]}\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3484\\378223959.py:2\u001b[0m, in \u001b[0;36mbuildDF\u001b[1;34m(filtered_sentences, sentences, useWeights, weights)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuildDF\u001b[39m(filtered_sentences, sentences, useWeights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, weights \u001b[38;5;241m=\u001b[39m []):\n\u001b[1;32m----> 2\u001b[0m     ensemble_dic \u001b[38;5;241m=\u001b[39m \u001b[43mgetTextRanks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_sentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     df \u001b[38;5;241m=\u001b[39m allCombs(ensemble_dic, useWeights, weights)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3484\\3197526573.py:5\u001b[0m, in \u001b[0;36mgetTextRanks\u001b[1;34m(filtered_sentences, sentences)\u001b[0m\n\u001b[0;32m      3\u001b[0m luhn_dic \u001b[38;5;241m=\u001b[39m luhn_algorithm(filtered_sentences, sentences)\n\u001b[0;32m      4\u001b[0m lsa_dic \u001b[38;5;241m=\u001b[39m lsa_summarization(filtered_sentences, sentences)\n\u001b[1;32m----> 5\u001b[0m tr_dic \u001b[38;5;241m=\u001b[39m \u001b[43mtextRank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_sentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m lex_dic \u001b[38;5;241m=\u001b[39m LexRank_algorithm(filtered_sentences, sentences)\n\u001b[0;32m      7\u001b[0m lda_dic \u001b[38;5;241m=\u001b[39m lda_algorithm(filtered_sentences, sentences)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3484\\167498644.py:29\u001b[0m, in \u001b[0;36mtextRank\u001b[1;34m(filtered_sentences, sentences)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sentences)):\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m j:\n\u001b[1;32m---> 29\u001b[0m             sim_mat[i][j] \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence_vectors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence_vectors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]   \n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#begining Graph stap\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1395\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[0;32m   1393\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[1;32m-> 1395\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n\u001b[0;32m   1397\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m X_normalized\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1817\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[0;32m   1814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1815\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not a supported axis\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m axis)\n\u001b[1;32m-> 1817\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1819\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1820\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthe normalize function\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1823\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1825\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:950\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n\u001b[0;32m    949\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmay_share_memory(array, array_orig):\n\u001b[1;32m--> 950\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;66;03m# always make a copy for non-numpy arrays\u001b[39;00m\n\u001b[0;32m    955\u001b[0m     array \u001b[38;5;241m=\u001b[39m _asarray_with_order(\n\u001b[0;32m    956\u001b[0m         array, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xp\u001b[38;5;241m=\u001b[39mxp\n\u001b[0;32m    957\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_array_api.py:186\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[0;32m    185\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_array_api.py:73\u001b[0m, in \u001b[0;36m_NumPyApiWrapper.asarray\u001b[1;34m(self, x, dtype, device, copy)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21masarray\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# Support copy in NumPy namespace\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m numpy\u001b[38;5;241m.\u001b[39masarray(x, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    for i in tqdm(range(start,end,1)):\n",
    "        try:\n",
    "            sentences = data[\"Sentences\"][i].split(ppSpecial)\n",
    "            filtered_sentences = data[\"Filtered Sent\"][i].split(ppSpecial)\n",
    "            df = buildDF(filtered_sentences, sentences, useWeights, weights)\n",
    "            df.to_csv(\"Document \" + i, index=False)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(\"Error\",i, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a72aee-68a5-4121-954c-83b4cfe1cfa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
